{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLfRBCjm10f-"
      },
      "source": [
        "# HPC Mini-Challenge 2 - Beschleunigung in Data Science\n",
        "## Teil 2: GPU\n",
        "#### FHNW - FS22\n",
        "\n",
        "Original von S. Suter, angepasst für das HS22 von S. Marcin\n",
        "\n",
        "Abgabe von: <font color='blue'>Joseph Weibel</font>\n",
        "\n",
        "#### Ressourcen\n",
        "* [Überblick GPU Programmierung](https://www.cherryservers.com/blog/introduction-to-gpu-programming-with-cuda-and-python)\n",
        "* [CUDA Basic Parts](https://nyu-cds.github.io/python-gpu/02-cuda/)\n",
        "* [Accelerate Code with CuPy](https://towardsdatascience.com/heres-how-to-use-cupy-to-make-numpy-700x-faster-4b920dda1f56)\n",
        "* Vorlesungen und Beispiele aus dem Informatikkurs PAC (parallel computing), siehe resourcen\n",
        "* CSCS \"High-Performance Computing with Python\" Kurs, Tag 3: \n",
        "    - JIT Numba GPU 1 + 2\n",
        "    - https://youtu.be/E4REVbCVxNQ\n",
        "    - https://github.com/eth-cscs/PythonHPC/tree/master/numba-cuda\n",
        "    - Siehe auch aktuelles Tutorial von 2021\n",
        "* [Google CoLab](https://colab.research.google.com/) oder ggf. eigene GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz9j6XIIJoqn",
        "outputId": "bc414e8f-df9f-4d8d-c5c3-cc847e680bfa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jan 13 14:22:31 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfDMy5al10gB",
        "outputId": "62eddb6e-d8ca-4447-f611-615836a40e50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 4 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.       ,  1.       ,  1.4142135, ..., 63.97656  , 63.98437  ,\n",
              "       63.992188 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Dummy Beispiel zum testen mit Numba\n",
        "\n",
        "import math\n",
        "from numba import vectorize\n",
        "import numpy as np\n",
        "\n",
        "@vectorize(['float32(float32)'], target='cuda')\n",
        "def gpu_sqrt(x):\n",
        "    return math.sqrt(x)\n",
        "  \n",
        "\n",
        "a = np.arange(4096,dtype=np.float32)\n",
        "gpu_sqrt(a)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBfhyWv1SnQV",
        "outputId": "0aee2b41-9139-41b9-b59b-96f02c1ac3d0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "subfolder = '001'\n",
        "folders = os.path.join('/content/drive/MyDrive/adni_png', subfolder)\n",
        "\n",
        "images = np.empty([7,256,170])\n",
        "idx = 0\n",
        "names = []\n",
        "for filename in os.listdir(folders):\n",
        "    if filename.endswith('.png') and '145' in filename:\n",
        "        with open(os.path.join(folders, filename), 'r') as f:\n",
        "            im = imageio.imread(f.name)\n",
        "            names.insert(idx, f.name[-17:-4])\n",
        "            images[idx,:,:] = im\n",
        "            print (names[idx], im.shape)\n",
        "            idx += 1\n",
        "            \n",
        "print(images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8bXzEUrSh7-",
        "outputId": "1ed19f59-a7d8-4a9d-cf0e-1974988adccc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "m1-1_slice145 (256, 170)\n",
            "m1-2_slice145 (256, 170)\n",
            "m3-2_slice145 (256, 170)\n",
            "m4-2_slice145 (256, 170)\n",
            "m4-1_slice145 (256, 170)\n",
            "m6-1_slice145 (256, 170)\n",
            "m3-1_slice145 (256, 170)\n",
            "(7, 256, 170)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = images[0]\n",
        "m = m -m.min() / m.max() - m.min() # normalize data \n",
        "u,s,vt = np.linalg.svd(m, full_matrices=False)"
      ],
      "metadata": {
        "id": "mS8O4WkCTuRK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "m = np.random.normal(size=(1000, 1000))\n",
        "u, s, vt = np.linalg.svd(m, full_matrices=False)"
      ],
      "metadata": {
        "id": "iW81HIzP5E1n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg9v73Xr10gC"
      },
      "source": [
        "### 5 GPU Rekonstruktion\n",
        "\n",
        "Implementiere eine SVD-Rekonstruktionsvariante auf der GPU oder in einem hybriden Setting. Code aus dem ersten Teil darf dabei verwendet werden. Wähle  bewusst, welche Teile des Algorithms in einem GPU Kernel implementiert werden und welche effizienter auf der CPU sind. Ziehe dafür Erkenntnisse aus dem ersten Teil mit ein. Es muss mindestens eine Komponente des Algorithmuses in einem GPU-Kernel implementiert werden. Dokumentiere Annahmen, welche du ggf. zur Vereinfachung triffst. Evaluiere, ob du mit CuPy oder Numba arbeiten möchtest. Diskutiere deine Entscheidungen in 150-200 Wörtern. \n",
        "\n",
        "Links:\n",
        "* [Examples: Matrix Multiplikation](https://numba.readthedocs.io/en/latest/cuda/examples.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bQ_svru010gC"
      },
      "outputs": [],
      "source": [
        "### BEGIN SOLUTION\n",
        "from numba import cuda, float32\n",
        "import math\n",
        "\n",
        "\n",
        "@cuda.jit\n",
        "def _reconstruct_svd_gpu_1(u, s, vt, reco):\n",
        "  x, y = cuda.grid(2)\n",
        "\n",
        "  if x < u.shape[0] and y < vt.shape[0]:\n",
        "    sum = 0\n",
        "    for k in range(s.shape[0]):\n",
        "      sum += u[x, k] * s[k] * vt[k, y]\n",
        "\n",
        "    reco[x, y] = sum\n",
        "\n",
        "def reconstruct_svd_gpu_1(u, s, vt, k, threads_per_block=32):\n",
        "  reco_h = np.zeros((u.shape[0], vt.shape[1]))\n",
        "\n",
        "  reco_d = cuda.to_device(reco_h)\n",
        "  u_d = cuda.to_device(u[:, 0:k])\n",
        "  s_d = cuda.to_device(s[0:k])\n",
        "  vt_d = cuda.to_device(vt[0:k, :])\n",
        "\n",
        "  n_blocks_x = math.ceil(u.shape[0] / threads_per_block)\n",
        "  n_blocks_y = math.ceil(vt.shape[0] / threads_per_block)\n",
        "\n",
        "  _reconstruct_svd_gpu_1[\n",
        "    (n_blocks_x, n_blocks_y), (threads_per_block, threads_per_block)\n",
        "  ](u_d, s_d, vt_d, reco_d)\n",
        "\n",
        "  return reco_d.copy_to_host()\n",
        "\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "reco = reconstruct_svd_gpu_1(u, s, vt, u.shape[1])\n",
        "np.testing.assert_array_almost_equal(reco, m, decimal=3)"
      ],
      "metadata": {
        "id": "7Yp2DK46SbZL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7r60ZT_10gD"
      },
      "source": [
        "<font color='blue'>Bei dieser einfachen Implementierung wird die gesamte Berechnung auf der GPU vorgenommen. Jeder Thread ist für ein einzelnes Pixel in der Rekonstruktion verantwortlich. Das Kürzen der Matrizen und Vektoren auf n Komponenten wird auf der CPU vorgenommen, beziehungsweise werden nur die nötigen Elemente auf die GPU kopiert. Dadurch wird verhindert, dass Elemente zur GPU kopiert werden, die dort gar nicht benötigt werden.\n",
        "\n",
        "Die Anzahl Threads pro Block kann dabei frei definiert werden. Kleinere Grössen können sinnvoll sein, um dadurch die Rekonstruktionsgrösse genau aufteilen zu können, so dass möglichst keine Threads leer laufen. Bei einer Breite von 2000 px wäre es sinnvoller 25 oder 16 statt 32 zu verwenden.\n",
        "TODO: stimmt das?\n",
        "\n",
        "Es wird numba verwendet, da damit die grundelegenden GPU-Operationen simuliert werden können. Zudem kann damit Python-Code geschrieben werden, der dann autoamtisch in C-Code übersetzt wird.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQz_TGwG10gD"
      },
      "source": [
        "#### 5.2 GPU-Kernel Performance\n",
        "\n",
        "##### 5.2.1 Blocks und Strided Access\n",
        "\n",
        "Links: \n",
        "* [Examples: Matrix Multiplikation](https://numba.readthedocs.io/en/latest/cuda/examples.html)\n",
        "* [NVIDIA Kapitel zu \"Strided Access\"](https://spaces.technik.fhnw.ch/multimediathek/file/cuda-best-practices-in-c)\n",
        "* https://developer.nvidia.com/blog/cublas-strided-batched-matrix-multiply/\n",
        "* https://developer.nvidia.com/blog/how-access-global-memory-efficiently-cuda-c-kernels/\n",
        "\n",
        "Führe 2-3 Experimente mit unterschiedlichen Blockkonfigurationen und Strided Access durch, auf welchen dein GPU-Kernel arbeitet. Messe die Performance des GPU-Kernels mittels geeigneten Funktionen. Welche Blockgrösse und welcher Strided Access hat sich bei dir basierend auf deinen Experimenten als am erfolgreichsten erwiesen? Welches sind deiner Meinung nach die Gründe dafür? Wie sind die Performance Unterschiede zwischen deiner CPU und PGU Implementierung? Diskutiere deine Analyse in ca. 200 Wörtern und ggf. mit Grafiken. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3aYPqmRk10gE"
      },
      "outputs": [],
      "source": [
        "### BEGIN SOLUTION\n",
        "@cuda.jit\n",
        "def _reconstruct_svd_gpu_2(u, s, vt, reco):\n",
        "  # each thread calculates the sum of products for a specific index (x, y)\n",
        "\n",
        "  x, y = cuda.grid(2)\n",
        "  local_x = cuda.threadIdx.x\n",
        "  local_y = cuda.threadIdx.y\n",
        "  threads_per_block = 32 # cuda.blockDim.x but must be constant\n",
        "  blocks_per_grid = cuda.gridDim.x\n",
        "\n",
        "  shrd_u = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "  shrd_s = cuda.shared.array(shape=(threads_per_block,), dtype=float32)\n",
        "  shrd_vt = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "\n",
        "  sum_of_products = float32(0.)\n",
        "  for block in range(blocks_per_grid):\n",
        "    # calculate sum of products per block\n",
        "    # the block is only moved to get the other values in the matrices u, s and vt\n",
        "    # the index for which the sum of product is calculated remains the same\n",
        "\n",
        "    shrd_u[local_y, local_x] = 0\n",
        "    if y < u.shape[0] and (block * threads_per_block + local_x) < u.shape[1]:\n",
        "      shrd_u[local_y, local_x] = u[y, block * threads_per_block + local_x]\n",
        "\n",
        "    if local_y == 0:\n",
        "      shrd_s[local_x] = 0\n",
        "      if (block * threads_per_block + local_x) < s.shape[0]:\n",
        "        # only first row in block loads shrd_s since it's a one-dimensional array\n",
        "        shrd_s[local_x] = s[block * threads_per_block + local_x]\n",
        "\n",
        "    shrd_vt[local_y, local_x] = 0\n",
        "    if x < vt.shape[1] and (block * threads_per_block + local_y) < vt.shape[0]:\n",
        "      shrd_vt[local_y, local_x] = vt[block * threads_per_block + local_y, x]\n",
        "\n",
        "    # wait until all tpb x tpb elements are filled\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    # start calculating the sum of products for index (y, x)\n",
        "    for i in range(threads_per_block):\n",
        "      # no checking of boundaries necessary since the warp executes the\n",
        "      # statement anyway and threads out of bound would have to wait anyway\n",
        "      sum_of_products += shrd_u[local_y, i] * shrd_s[i] * shrd_vt[i, local_x]\n",
        "\n",
        "    # wait until all threads have computed their sum of products before we move\n",
        "    # to the next block as the shared values will be overridden with the next\n",
        "    # iteration\n",
        "    cuda.syncthreads()\n",
        "\n",
        "  if y < reco.shape[0] and x < reco.shape[1]:\n",
        "    reco[y, x] = sum_of_products\n",
        "\n",
        "def reconstruct_svd_gpu_2(u, s, vt, k):\n",
        "  threads_per_block = 32\n",
        "  reco_h = np.zeros((u.shape[0], vt.shape[1]))\n",
        "\n",
        "  reco_d = cuda.to_device(reco_h)\n",
        "  u_d = cuda.to_device(u[:, 0:k])\n",
        "  s_d = cuda.to_device(s[0:k])\n",
        "  vt_d = cuda.to_device(vt[0:k, :])\n",
        "\n",
        "  grid_y_max = max(u.shape[0], k)\n",
        "  grid_x_max = max(k, vt.shape[1])\n",
        "\n",
        "  n_blocks_x = math.ceil(grid_x_max / threads_per_block)\n",
        "  n_blocks_y = math.ceil(grid_y_max / threads_per_block)\n",
        "\n",
        "  _reconstruct_svd_gpu_2[\n",
        "    (n_blocks_x, n_blocks_y), (threads_per_block, threads_per_block)\n",
        "  ](u_d, s_d, vt_d, reco_d)\n",
        "\n",
        "  return reco_d.copy_to_host()\n",
        "\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reco = reconstruct_svd_gpu_2(u, s, vt, u.shape[1])\n",
        "np.testing.assert_array_almost_equal(reco, m, decimal=3)\n"
      ],
      "metadata": {
        "id": "rxzNDrzE6SwG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQJeUtV610gF"
      },
      "source": [
        "<font color='blue'>Die erste Version hat ein schlechtes Verhältnis von Memory- zu Computation-Operationen. Es wird bei jeder Berechnung dreimal aufs Memory zugegriffen, ohne dass diese Werte nochmals verwendet werden. Diese optimierte Variante kopiert nun blockweise die benötigten Werte ins Shared-Memory wo sie von allen Threads desselben Blocks ebenfalls verwendet werden können. Da bei diesen Matrixmultiplikationen sehr viele Elemente wiederverwendet werden können, ist diese Implementierung um einiges schneller als die letzte, auch wenn nach wie vor alle Elemente mehrmals kopiert werden, da sie auch von anderen Blocks verwendet werden.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJZydur_10gF"
      },
      "source": [
        "##### 5.2.2 Memoryallokation auf der GPU\n",
        "Führe 2-3 Experimente durch in welchem du unterschiedliche Varianten des Transfers der Daten bzw. der Memory-Allokation auf die GPU miteinander vergleichst. Messe die Varianten mittels geeigneten Methoden. Als Beispiel können hier z.B. unterschiedlich grosse Packages an Daten auf die GPU kopiert und dann verarbeitet werden oder die Daten werden in unterschiedliche Memory-Typen geladen.\n",
        "\n",
        "Links:\n",
        "* [Best Practices Memory Optimizations](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#memory-optimizations)\n",
        "* [Examples: Matrix Multiplikation und Shared Memory](https://numba.readthedocs.io/en/latest/cuda/examples.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Antwort\n",
        "\n",
        "<font color='blue'></font>"
      ],
      "metadata": {
        "id": "XdDmxc38f0Lg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tZCkT52c10gF"
      },
      "outputs": [],
      "source": [
        "### BEGIN SOLUTION\n",
        "@cuda.jit\n",
        "def _reconstruct_svd_gpu_3(u, s, vt, reco):\n",
        "  # each thread calculates the sum of products for a specific index (x, y)\n",
        "\n",
        "  x, y = cuda.grid(2)\n",
        "  local_x = cuda.threadIdx.x\n",
        "  local_y = cuda.threadIdx.y\n",
        "  threads_per_block = 32 # cuda.blockDim.x but must be constant\n",
        "  blocks_per_grid = cuda.gridDim.x\n",
        "\n",
        "  shrd_u = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "  shrd_s = cuda.shared.array(shape=(threads_per_block,), dtype=float32)\n",
        "  shrd_vt = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "\n",
        "  sum_of_products = float32(0.)\n",
        "  for block in range(blocks_per_grid):\n",
        "    # calculate sum of products per block\n",
        "    # the block is only moved to get the other values in the matrices u, s and vt\n",
        "    # the index for which the sum of product is calculated remains the same\n",
        "\n",
        "    shrd_u[local_y, local_x] = 0\n",
        "    if y < u.shape[0] and (block * threads_per_block + local_x) < u.shape[1]:\n",
        "      # copy values in transposed order\n",
        "      shrd_u[local_y, local_x] = u[y, block * threads_per_block + local_x]\n",
        "\n",
        "    if local_y == 0:\n",
        "      shrd_s[local_x] = 0\n",
        "      if (block * threads_per_block + local_x) < s.shape[0]:\n",
        "        # only first row in block loads shrd_s since it's a one-dimensional array\n",
        "        shrd_s[local_x] = s[block * threads_per_block + local_x]\n",
        "\n",
        "    shrd_vt[local_x, local_y] = 0\n",
        "    if x < vt.shape[1] and (block * threads_per_block + local_y) < vt.shape[0]:\n",
        "      shrd_vt[local_x, local_y] = vt[block * threads_per_block + local_y, x]\n",
        "\n",
        "    # wait until all tpb x tpb elements are filled\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    # start calculating the sum of products for index (y, x)\n",
        "    for i in range(threads_per_block):\n",
        "      # no checking of boundaries necessary since the warp executes the\n",
        "      # statement anyway and threads out of bound would have to wait anyway\n",
        "\n",
        "      # read values from shred_u in transposed order\n",
        "      sum_of_products += shrd_u[local_y, i] * shrd_s[i] * shrd_vt[local_x, i]\n",
        "\n",
        "    # wait until all threads have computed their sum of products before we move\n",
        "    # to the next block as the shared values will be overridden with the next\n",
        "    # iteration\n",
        "    cuda.syncthreads()\n",
        "\n",
        "  if y < reco.shape[0] and x < reco.shape[1]:\n",
        "    reco[y, x] = sum_of_products\n",
        "\n",
        "def reconstruct_svd_gpu_3(u, s, vt, k):\n",
        "  threads_per_block = 32\n",
        "  reco_h = np.zeros((u.shape[0], vt.shape[1]))\n",
        "\n",
        "  reco_d = cuda.to_device(reco_h)\n",
        "  u_d = cuda.to_device(u[:, 0:k])\n",
        "  s_d = cuda.to_device(s[0:k])\n",
        "  vt_d = cuda.to_device(vt[0:k, :])\n",
        "\n",
        "  grid_y_max = max(u.shape[0], k)\n",
        "  grid_x_max = max(k, vt.shape[1])\n",
        "\n",
        "  n_blocks_x = math.ceil(grid_x_max / threads_per_block)\n",
        "  n_blocks_y = math.ceil(grid_y_max / threads_per_block)\n",
        "\n",
        "  _reconstruct_svd_gpu_3[\n",
        "    (n_blocks_x, n_blocks_y), (threads_per_block, threads_per_block)\n",
        "  ](u_d, s_d, vt_d, reco_d)\n",
        "\n",
        "  return reco_d.copy_to_host()\n",
        "\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reco = reconstruct_svd_gpu_3(u, s, vt, u.shape[1])\n",
        "np.testing.assert_array_almost_equal(reco, m, decimal=3)\n"
      ],
      "metadata": {
        "id": "nz_P46K2frSw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW5QvzaY10gG"
      },
      "source": [
        "Was sind deine Erkenntnisse bzgl. GPU-Memory-Allokation und des Daten-Transferes auf due GPU? Wie hast du ggf. deine Implementierung aus 5.1 angepasst? Diskutiere deine Antwort in ca. 150-200 Wörtern."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQIv_HuO10gG"
      },
      "source": [
        "<font color='blue'>Diese Implementierung versucht Bank-Conflicts beim Zugriff auf das Shared-Memory zu vermeiden. Auf `shrt_vt` wurde bisher in einem Warp jeweils pro Iteration auf dieselbe Spalte zugegriffen. Dadurch kam es zu 32 Bank Conflicts, was dazu führte, dass jedes Element separat aus dem Shared-Memory abgerufen werden musste. Neu ist `shrt_vt` transponiert, so dass im Warp jeweils eine ganze Zeile abgerufen werden kann.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mcY4-4w10gG"
      },
      "source": [
        "##### 5.2.3 Bonus: Memoryoptimierung\n",
        "Optimiere die Memory-Allokation in deiner Implementierung, so dass du einen Leistungssteigerung zu einer anderen Variante demonstrieren kannst."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Antwort\n"
      ],
      "metadata": {
        "id": "DzhQFio_0sn0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jR7tKA0-10gH"
      },
      "outputs": [],
      "source": [
        "### BEGIN SOLUTION\n",
        "@cuda.jit\n",
        "def _reconstruct_svd_gpu_4(u, s, vt, reco):\n",
        "  # each thread calculates the sum of products for a specific index (x, y)\n",
        "\n",
        "  x, y = cuda.grid(2)\n",
        "  local_x = cuda.threadIdx.x\n",
        "  local_y = cuda.threadIdx.y\n",
        "  threads_per_block = 32 # cuda.blockDim.x but must be constant\n",
        "  blocks_per_grid = cuda.gridDim.x\n",
        "\n",
        "  shrd_u = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "  shrd_s = cuda.shared.array(shape=(threads_per_block,), dtype=float32)\n",
        "  shrd_vt = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "  shrd_u_pre = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "  shrd_s_pre = cuda.shared.array(shape=(threads_per_block,), dtype=float32)\n",
        "  shrd_vt_pre = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "\n",
        "  shrd_u_pre[local_y, local_x] = 0\n",
        "  if y < u.shape[0] and local_x < u.shape[1]:\n",
        "    # copy values in transposed order\n",
        "    shrd_u_pre[local_y, local_x] = u[y, local_x]\n",
        "\n",
        "  if local_y == 0:\n",
        "    shrd_s_pre[local_x] = 0\n",
        "    if local_x < s.shape[0]:\n",
        "      # only first row in block loads shrd_s since it's a one-dimensional array\n",
        "      shrd_s_pre[local_x] = s[local_x]\n",
        "\n",
        "  shrd_vt_pre[local_x, local_y] = 0\n",
        "  if x < vt.shape[1] and local_y < vt.shape[0]:\n",
        "    shrd_vt_pre[local_x, local_y] = vt[local_y, x]\n",
        "\n",
        "  # wait until all tpb x tpb elements are filled\n",
        "  cuda.syncthreads()\n",
        "\n",
        "  sum_of_products = float32(0.)\n",
        "  for block in range(blocks_per_grid):\n",
        "    # calculate sum of products per block\n",
        "    # the block is only moved to get the other values in the matrices u, s and vt\n",
        "    # the index for which the sum of product is calculated remains the same\n",
        "\n",
        "    # swap shared memory blocks\n",
        "    shrd_u, shrd_u_pre = shrd_u_pre, shrd_u\n",
        "    shrd_s, shrd_s_pre = shrd_s_pre, shrd_s\n",
        "    shrd_vt, shrd_vt_pre = shrd_vt_pre, shrd_vt\n",
        "\n",
        "    next_block = block + 1\n",
        "\n",
        "    # load next block\n",
        "    shrd_u_pre[local_y, local_x] = 0\n",
        "    if y < u.shape[0] and (next_block * threads_per_block + local_x) < u.shape[1]:\n",
        "      # copy values in transposed order\n",
        "      shrd_u_pre[local_y, local_x] = u[y, next_block * threads_per_block + local_x]\n",
        "\n",
        "    if local_y == 0:\n",
        "      shrd_s_pre[local_x] = 0\n",
        "      if (next_block * threads_per_block + local_x) < s.shape[0]:\n",
        "        # only first row in block loads shrd_s since it's a one-dimensional array\n",
        "        shrd_s_pre[local_x] = s[next_block * threads_per_block + local_x]\n",
        "\n",
        "    shrd_vt_pre[local_x, local_y] = 0\n",
        "    if x < vt.shape[1] and (next_block * threads_per_block + local_y) < vt.shape[0]:\n",
        "      shrd_vt_pre[local_x, local_y] = vt[next_block * threads_per_block + local_y, x]\n",
        "\n",
        "    # start calculating the sum of products for index (y, x) and the current block\n",
        "    for i in range(threads_per_block):\n",
        "      # no checking of boundaries necessary since the warp executes the\n",
        "      # statement anyway and threads out of bound would have to wait anyway\n",
        "\n",
        "      # read values from shred_u in transposed order\n",
        "      sum_of_products += shrd_u[local_y, i] * shrd_s[i] * shrd_vt[local_x, i]\n",
        "\n",
        "    # wait until all threads have computed their sum of products before we move\n",
        "    # to the next block as the shared values will be overridden with the next\n",
        "    # iteration\n",
        "    cuda.syncthreads()\n",
        "\n",
        "  if y < reco.shape[0] and x < reco.shape[1]:\n",
        "    reco[y, x] = sum_of_products\n",
        "\n",
        "def reconstruct_svd_gpu_4(u, s, vt, k):\n",
        "  threads_per_block = 32\n",
        "  reco_h = np.zeros((u.shape[0], vt.shape[1]))\n",
        "\n",
        "  reco_d = cuda.to_device(reco_h)\n",
        "  u_d = cuda.to_device(u[:, 0:k])\n",
        "  s_d = cuda.to_device(s[0:k])\n",
        "  vt_d = cuda.to_device(vt[0:k, :])\n",
        "\n",
        "  grid_y_max = max(u.shape[0], k)\n",
        "  grid_x_max = max(k, vt.shape[1])\n",
        "\n",
        "  n_blocks_x = math.ceil(grid_x_max / threads_per_block)\n",
        "  n_blocks_y = math.ceil(grid_y_max / threads_per_block)\n",
        "\n",
        "  _reconstruct_svd_gpu_4[\n",
        "    (n_blocks_x, n_blocks_y), (threads_per_block, threads_per_block)\n",
        "  ](u_d, s_d, vt_d, reco_d)\n",
        "\n",
        "  return reco_d.copy_to_host()\n",
        "\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reco = reconstruct_svd_gpu_4(u, s, vt, u.shape[1])\n",
        "np.testing.assert_array_almost_equal(reco, m, decimal=3)\n"
      ],
      "metadata": {
        "id": "qPUsmKNS6oH-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>Bei dieser Optimierung passiert der Kopiervorgang vom Shared-Memory ins globale Memory nun asynchron zu den Berechnungen. Währenddem das Resultat für den aktuellen Block berechnet wird, werden bereits die Elemente des nächsten Blocks kopiert, so dass sie teilweise oder gar vollständig bereitstehen, wenn die Berechnungen des nächsten Blocks anstehen. Dazu wird jedoch doppelt soviel Speicher im Shared-Memory benötigt. Die GPU kann so aber besser ausgelastet werden.</font>"
      ],
      "metadata": {
        "id": "3RL_2wM05HyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### BEGIN SOLUTION\n",
        "@cuda.jit\n",
        "def _reconstruct_svd_gpu_5(u, s, vt, reco):\n",
        "  # each thread calculates the sum of products for a specific index (x, y)\n",
        "\n",
        "  x, y = cuda.grid(2)\n",
        "  local_x = cuda.threadIdx.x\n",
        "  local_y = cuda.threadIdx.y\n",
        "  threads_per_block = 32 # cuda.blockDim.x but must be constant\n",
        "  blocks_per_grid = cuda.gridDim.x\n",
        "\n",
        "  shrd_u = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "  shrd_s = cuda.shared.array(shape=(threads_per_block,), dtype=float32)\n",
        "  shrd_vt = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "  shrd_u_pre = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "  shrd_s_pre = cuda.shared.array(shape=(threads_per_block,), dtype=float32)\n",
        "  shrd_vt_pre = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "\n",
        "  shrd_u_pre[local_y, local_x] = 0\n",
        "  if y < u.shape[0] and local_x < u.shape[1]:\n",
        "    # copy values in transposed order\n",
        "    shrd_u_pre[local_y, local_x] = u[y, local_x]\n",
        "\n",
        "  if local_y == 0:\n",
        "    shrd_s_pre[local_x] = 0\n",
        "    if local_x < s.shape[0]:\n",
        "      # only first row in block loads shrd_s since it's a one-dimensional array\n",
        "      shrd_s_pre[local_x] = s[local_x]\n",
        "\n",
        "  shrd_vt_pre[local_y, local_x] = 0\n",
        "  if x < vt.shape[1] and local_y < vt.shape[0]:\n",
        "    shrd_vt_pre[local_y, local_x] = vt[local_y, x]\n",
        "\n",
        "  # wait until all tpb x tpb elements are filled\n",
        "  cuda.syncthreads()\n",
        "\n",
        "  sum_of_products = float32(0.)\n",
        "  for block in range(blocks_per_grid):\n",
        "    # calculate sum of products per block\n",
        "    # the block is only moved to get the other values in the matrices u, s and vt\n",
        "    # the index for which the sum of product is calculated remains the same\n",
        "\n",
        "    # swap shared memory blocks\n",
        "    shrd_u, shrd_u_pre = shrd_u_pre, shrd_u\n",
        "    shrd_s, shrd_s_pre = shrd_s_pre, shrd_s\n",
        "    shrd_vt, shrd_vt_pre = shrd_vt_pre, shrd_vt\n",
        "\n",
        "    next_block = block + 1\n",
        "\n",
        "    # load next block\n",
        "    shrd_u_pre[local_y, local_x] = 0\n",
        "    if y < u.shape[0] and (next_block * threads_per_block + local_x) < u.shape[1]:\n",
        "      # copy values in transposed order\n",
        "      shrd_u_pre[local_y, local_x] = u[y, next_block * threads_per_block + local_x]\n",
        "\n",
        "    if local_y == 0:\n",
        "      shrd_s_pre[local_x] = 0\n",
        "      if (next_block * threads_per_block + local_x) < s.shape[0]:\n",
        "        # only first row in block loads shrd_s since it's a one-dimensional array\n",
        "        shrd_s_pre[local_x] = s[next_block * threads_per_block + local_x]\n",
        "\n",
        "    shrd_vt_pre[local_y, local_x] = 0\n",
        "    if x < vt.shape[1] and (next_block * threads_per_block + local_y) < vt.shape[0]:\n",
        "      shrd_vt_pre[local_y, local_x] = vt[next_block * threads_per_block + local_y, x]\n",
        "\n",
        "    # start calculating the sum of products for index (y, x) and the current block\n",
        "    for i in range(threads_per_block):\n",
        "      # no checking of boundaries necessary since the warp executes the\n",
        "      # statement anyway and threads out of bound would have to wait anyway\n",
        "\n",
        "      # read values from shred_u in transposed order\n",
        "      sum_of_products += shrd_u[local_y, i] * shrd_s[i] * shrd_vt[i, local_x]\n",
        "\n",
        "    # wait until all threads have computed their sum of products before we move\n",
        "    # to the next block as the shared values will be overridden with the next\n",
        "    # iteration\n",
        "    cuda.syncthreads()\n",
        "\n",
        "  if y < reco.shape[0] and x < reco.shape[1]:\n",
        "    reco[y, x] = sum_of_products\n",
        "\n",
        "def reconstruct_svd_gpu_5(u, s, vt, k):\n",
        "  threads_per_block = 32\n",
        "  reco_h = np.zeros((u.shape[0], vt.shape[1]))\n",
        "\n",
        "  reco_d = cuda.to_device(reco_h)\n",
        "  u_d = cuda.to_device(u[:, 0:k])\n",
        "  s_d = cuda.to_device(s[0:k])\n",
        "  vt_d = cuda.to_device(vt[0:k, :])\n",
        "\n",
        "  grid_y_max = max(u.shape[0], k)\n",
        "  grid_x_max = max(k, vt.shape[1])\n",
        "\n",
        "  n_blocks_x = math.ceil(grid_x_max / threads_per_block)\n",
        "  n_blocks_y = math.ceil(grid_y_max / threads_per_block)\n",
        "\n",
        "  _reconstruct_svd_gpu_5[\n",
        "    (n_blocks_x, n_blocks_y), (threads_per_block, threads_per_block)\n",
        "  ](u_d, s_d, vt_d, reco_d)\n",
        "\n",
        "  return reco_d.copy_to_host()\n",
        "\n",
        "### END SOLUTION"
      ],
      "metadata": {
        "id": "E4CErjPPocD5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reco = reconstruct_svd_gpu_5(u, s, vt, u.shape[1])\n",
        "np.testing.assert_array_almost_equal(reco, m, decimal=3)\n"
      ],
      "metadata": {
        "id": "1jaqQn-eo2Eg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>Diese letzte Variante ist nahezu identisch mit der vorhergehenden und setzt auch auf das Preloading vom globalen ins shared Memory. Jedoch werden die Werte aus der Matrix $V^T$ in der ursprünglichen Reihenfolge ins Shared-Memory übernommen und nicht transponiert, um beim Vergleich der Laufzeiten die Optimierung des Vorladens besser quantifizieren zu können.</font>"
      ],
      "metadata": {
        "id": "jDDCKY56sh7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### BEGIN SOLUTION\n",
        "import pandas as pd\n",
        "import timeit\n",
        "\n",
        "def plot_runtimes(names, fncs):\n",
        "    times = []\n",
        "    for fnc in fncs:\n",
        "        times.append(timeit.repeat(lambda: fnc(u, s, vt, u.shape[0]), number=3, repeat=30))\n",
        "        \n",
        "    times = np.array(times)\n",
        "    \n",
        "    y = times.mean(axis=1)\n",
        "    plt.figure(figsize = (12, 7))\n",
        "    plt.errorbar(\n",
        "        names,\n",
        "        y,\n",
        "        times.std(axis=1),\n",
        "        linestyle='None',\n",
        "        marker='o', \n",
        "        capsize=10\n",
        "    )\n",
        "    plt.title('Laufzeiten')\n",
        "    plt.xlabel('Variante')\n",
        "    plt.ylabel('Dauer [s] (log)')\n",
        "    plt.yscale('log')\n",
        "    plt.show()\n",
        "\n",
        "    results = pd.DataFrame({'fnc': names, 'mean duration (s)': y})\n",
        "    results.fnc = results.fnc.str.replace('\\n', '')\n",
        "    results\n",
        "\n",
        "plot_runtimes(\n",
        "    ['basic', 'memory optimised', 'avoiding bank conflicts', 'preloading shared memory\\n and avoiding bank conflicts', 'preloading shared memory'],\n",
        "    [reconstruct_svd_gpu_1, reconstruct_svd_gpu_2, reconstruct_svd_gpu_3, reconstruct_svd_gpu_4, reconstruct_svd_gpu_5]\n",
        ")\n",
        "\n",
        "\n",
        "### END SOLUTION"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "4PWZ5f6U6k7L",
        "outputId": "b9286759-ce8e-42c1-8282-9e172029ef6c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>Beim Vergleich der Laufzeiten dieser vier GPU-Varianten lässt sich schnell erkennen, dass die Basic-Variante die Vorteile einer GPU nicht nutzt, da sie das Paradigma Single-Instruction-Multiple-Data nicht optimal anwendet. Für jede einzelne Berechnung müssen drei Werte aus dem Global-Memory der GPU kopiert werden, was viel Zeit kostet.\n",
        "\n",
        "Die optimierte Variante kopiert blockweise Werte der zwei Matrizen und des Vektors in das Shared-Memory, wo die Werte vom gesamten Threadblock verwendet werden können. Dadurch wird die Anzahl Zugriffe aufs Global-Memory stark reduziert, was sich einer viel kürzeren Laufzeit bemerkbar macht. Die Vermeidung von Bank-Conflicts bei der dritten Version scheint nicht wie erhofft zu funktionieren. Die Laufzeit erhöht sich bei dieser Version wieder stark, was auch bei der vierten Variante erkennbar ist. Das Preloading vom Global-Memory ins Shared-Memory scheint auch nicht ganz wie erhofft zu funktioniert. Die Laufzeit ist bei dieser Version auch höher als bei Variante 2. Möglicherweise können durch den doppelt so hohen Shared-Memoryverbrauch nicht mehr gleich viele Threads in einem Threadblock gleichzeitig ausgeführt werden, da für die Verwaltung der Threads nicht ausreichend Memory zur Verfügung steht. Die reduzierte Gleichläufigkeit hat dabei einen viel grösseren negativen Effekt als das Vorladen des Memorys wieder wett machen kann.</font>"
      ],
      "metadata": {
        "id": "XqCPW0p2_qcR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-a9oB8m10gH"
      },
      "source": [
        "#### 5.3 NVIDIA Profiler\n",
        "\n",
        "Benutze einen Performance Profiler von NVIDIA, um Bottlenecks in deinem Code zu identifizieren bzw. unterschiedliche Implementierungen (Blocks, Memory etc.) zu vergleichen. \n",
        "\n",
        "* Siehe Beispiel example_profiling_CUDA.ipynb\n",
        "* [Nsight](https://developer.nvidia.com/nsight-visual-studio-edition) für das Profiling des Codes und die Inspektion der Ergebnisse (neuste Variante)\n",
        "* [nvprof](https://docs.nvidia.com/cuda/profiler-users-guide/index.html#nvprof-overview)\n",
        "* [Nvidia Visual Profiler](https://docs.nvidia.com/cuda/profiler-users-guide/index.html#visual)\n",
        "\n",
        "> Du kannst NVIDIA Nsights Systems und den Nvidia Visual Profiler auf deinem PC installieren und die Leistungsergebnisse aus einer Remote-Instanz visualisieren, auch wenn du keine GPU an/in deinem PC hast. Dafür kannst du die ``*.qdrep`` Datei generieren und danach lokal laden.\n",
        "\n",
        "\n",
        "Dokumentiere deine Analyse ggf. mit 1-2 Visualisierungen und beschreibe in 3-5 Sätzen, welche Bottlenecks du gefunden bzw. entschärft hast."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\">Alle Profiling-Reports wurden mit folgendem Befehl generiert. Das Python-Script berechnet mit SVD die drei Komponenten $U$, $S$ und $V^T$ für eine 2000 x 2000 Elemente grosse Matrix und ruft anschliessend die jeweilige Rekonstruktions-Funktion mit diesen drei Werten auf. Dabei werden alle Komponenten zur Rekonstruktion verwendet.</font>"
      ],
      "metadata": {
        "id": "3IUVged-L4I7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !ncu -f -o reconstruct_svd_gpu_6 --set full --target-processes all python /content/drive/MyDrive/reconstruct_svd_gpu_6.py"
      ],
      "metadata": {
        "id": "X0MM9kUPrVJ4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Variante 2\n",
        "\n",
        "<img src=\"images/reconstruct_svd_gpu_2.png\" alt=\"Report für Variante 2\" width=\"500\"/>\n",
        "\n",
        "<font color=\"blue\">Dass mit dieser Variante eine gute Laufzeit erzielt werden kann, konnten wir bereits feststellen. Auch im Report lässt sich dies erkennen. Einerseits zeigt *NVIDIA Nsight Compute* keine Warnungen an, andererseits sehen wir dass auch an den hohen für die GPU Utilization. Streaming Multiprocessors und das Memory werden zu über 75 % ausgelastet. Wir bewegen uns zudem bei fast 9 FLOPs pro Byte. Es werden also relativ viele Operation pro Memoryzugriff durchgeführt.\n",
        "\n",
        "Im Abschnitt zum Memory-Workload, sehen wir, dass sehr viele Write- und noch mehr Read-Requests ins Shared-Memory abgesetzt werden. Das wird durch die vielen Schreib- und Lesezugriffe für die zwei Matrizen und den einen Vektor verursacht, die wir zur Optimierung der Geschwindigkeit ins Shared-Memory kopieren. Beim Shared-Memory sehen wir zudem, dass keinerleit Bank-Conflicts entstanden sind. Die am meisten beanspruchste Komponente, die LSU-Pipeline, die für die Memory-Zugriffe verantwortlich ist, ist zu 76 % ausgelastet. Es werden also nach wie vor viele Memory-Zugriffe gemacht.</font>"
      ],
      "metadata": {
        "id": "OLJoPDj-LTFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Variante 3\n",
        "\n",
        "<img src=\"images/reconstruct_svd_gpu_3.png\" alt=\"Report für Variante 3\" width=\"500\"/>\n",
        "\n",
        "<font color=\"blue\">Diese Variante, die eigentlich die Bank-Conflicts reduzieren sollte, führte nun dazu, dass nun sehr viele solche entstehen, wie man bei der Memory-Auswertung sehen kann. Anscheinend war die Verbesserung gar nicht nötig. Aufgrund der vielen Bank Conflicts tauchen nun auch einige Warnungen am Ende des Reports auf. Hier wird der uncoalesced Shared-Memoryzugriff bemängelt. Die Auslastung von *SOL L1/TEX Cache* ist nahezu bei 100 %, was das Bottleneck bei dieser Variante zu sein scheint.\n",
        "\n",
        "Dass die vielen Bank Conflicts die Laufzeit stark verlängern, sieht man oben an der Duration und der Elapsed Cycles, die nun viel höher sind als noch beim letzten Report. Die Wavefronts, also die tatsächlichen separaten Zugriffe aufs Shared-Memory, haben sich fast verzwölffacht (von 768'144'384 auf 8'705'636'352). Ausserdem ist deshalb der Streaming Multiprocessor viel weniger stark ausgelastet (weniger als 10 %). Deshalb befinden sich auch die Warps allermeistens im Zustand *Stall MIO Throttle*, also sie warten bis die Memory-Komponente wieder verfügbar ist, um weitere Memory-Zugriffe auszuführen.\n",
        "\n",
        "Die Verbesserung war wohl deswegen nicht nötig, da in der urspürnglichen Varianten bei `shrd_vt[i, local_x]` die Variable `i` für alle Threads imselben Warp konstant ist und nur `local_x` ändert. So wurden jeweils unterschiedliche Spalten abgerufen, was einen coalesced Zugriff erlaubt. Durch die Umkehrung zu `shrd_vt[local_x, i]` werden nun alle Werte aus derselben Spalte abgerufen, was diese vielen Bank Conflicts provoziert. Bei `shrd_u[local_y, i]` gibt es ebenfalls keine Bank-Conflicts, obwohl `i` also die Spalte für alle Threads im gleichen Warp konstant ist. Dies weil `local_y` auch konstant sein dürfte, da Warps aus Threads in der gleichen Zeile bestehen. Hier wird also derselbe Wert für alle Threads im Warp abgerufen.</font>\n",
        "\n",
        "##### Allgemein\n",
        "\n",
        "Bei allen Varianten können aufgrund der wenigen If-Abfragen im Code hohe Werte bei der *Branch Efficency* erzielt werden. Das bedeutet, dass wenige Threads auf andere Threads müssen, weil eine If-Abfrage für sie negativ ausfällt. \n"
      ],
      "metadata": {
        "id": "nVdfuhXCQQnM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Variante 5\n",
        "\n",
        "<img src=\"images/reconstruct_svd_gpu_5.png\" alt=\"Report für Variante 5\" width=\"500\"/>\n",
        "\n",
        "<font color=\"blue\">Diese Variante setzt auf das Preloading des nächsten Blocks. Dabei werden weniger `syncthreads` im Code verwendet. Im Report dazu sehen wir, dass so im Vergleich zur Variante 2 die Auslastung des Streaming Multiprocessors und auch der ALU erhöht werden konnte. Es scheinen aber zu wenig Ressourcen (Schedulers) zur Verfügung zu stehen, um genügend Warps ausführen zu können. Viele Warps befinden sich im Zustand, so dass sie eigentlich ausgeführt werden könnten, aber aufgrund der vielen anderen bereiten Warps müssen sie im Schnitt 5 Zyklen warten, bis sie wirklich ausgeführt werden können (*Stall Not Selected*). Auch warten relativ viele Warps auf die Math-Pipeline (mutmasslich die ausgelastete ALU). \n",
        "\n",
        "Da weniger `syncthreads` verwendet wurden, hat sich auch die Wartezeit beim Zustand *Stall Barrier* im Vergleich zu Report 2 reduziert. Die GPU-Komponenten scheinen dadurch also ungleichmässiger ausgelastet zu sein, was sich in einer doppelt so hohen Duration und doppelt so vielen elapsed Cycles ausdrückt.</font>"
      ],
      "metadata": {
        "id": "6elQoqMJS8Te"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Variante 6\n",
        "\n",
        "<font color=\"blue\">Um die in Variante 5 identifizierten Probleme zu beheben, wurde eine sechste Variante des Kernels implementiert. Die grösste Optimierung besteht hier darin, dass die Threads per Block von 32 x 32 auf 16 x 16 reduziert wurden, so dass auch die Shared-Memory pro Threadblock verkleinert werden können. Dies in der Hoffnung, dass so mehr Schedulers bereitstehen und mehr Warps gleichzeitig ausgeführt werden können.\n",
        "\n",
        "Zudem wurde eine If-Abfrage eingebaut, so dass nach dem letzten Block keine Schreibzugriffe aufs Shared-Memory mehr durchgeführt werden und es existiert nun nur noch eine `syncthreads`-Anweisung. Diese befindet sich genau vor dem Code-Block bei der das Shared-Memory bereitstehen muss und nicht mehr einige Anweisungen vorher. Damit kann die unnötige `syncthreads`-Anweisung nach dem letzten Block vermieden werden. So kann der Thread früher terminieren und befindet sich zum Schluss nicht noch in einem Wartezustand. Dies wird die Laufzeit nicht wirklich verkürzen, aber diese Warps beeinflussen den Report etwas weniger mit diesem Zustand.</font>"
      ],
      "metadata": {
        "id": "Hwt4-kJxVkxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### BEGIN SOLUTION\n",
        "@cuda.jit\n",
        "def _reconstruct_svd_gpu_6(u, s, vt, reco):\n",
        "  # each thread calculates the sum of products for a specific index (x, y)\n",
        "\n",
        "  x, y = cuda.grid(2)\n",
        "  local_x = cuda.threadIdx.x\n",
        "  local_y = cuda.threadIdx.y\n",
        "  threads_per_block = 16 # cuda.blockDim.x but must be constant\n",
        "  blocks_per_grid = cuda.gridDim.x\n",
        "\n",
        "  shrd_u = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "  shrd_s = cuda.shared.array(shape=(threads_per_block,), dtype=float32)\n",
        "  shrd_vt = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "  shrd_u_pre = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "  shrd_s_pre = cuda.shared.array(shape=(threads_per_block,), dtype=float32)\n",
        "  shrd_vt_pre = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "\n",
        "  shrd_u_pre[local_y, local_x] = 0\n",
        "  if y < u.shape[0] and local_x < u.shape[1]:\n",
        "    # copy values in transposed order\n",
        "    shrd_u_pre[local_y, local_x] = u[y, local_x]\n",
        "\n",
        "  if local_y == 0:\n",
        "    shrd_s_pre[local_x] = 0\n",
        "    if local_x < s.shape[0]:\n",
        "      # only first row in block loads shrd_s since it's a one-dimensional array\n",
        "      shrd_s_pre[local_x] = s[local_x]\n",
        "\n",
        "  shrd_vt_pre[local_y, local_x] = 0\n",
        "  if x < vt.shape[1] and local_y < vt.shape[0]:\n",
        "    shrd_vt_pre[local_y, local_x] = vt[local_y, x]\n",
        "\n",
        "  sum_of_products = float32(0.)\n",
        "  for block in range(blocks_per_grid):\n",
        "    # calculate sum of products per block\n",
        "    # the block is only moved to get the other values in the matrices u, s and vt\n",
        "    # the index for which the sum of product is calculated remains the same\n",
        "\n",
        "    # swap shared memory blocks\n",
        "    shrd_u, shrd_u_pre = shrd_u_pre, shrd_u\n",
        "    shrd_s, shrd_s_pre = shrd_s_pre, shrd_s\n",
        "    shrd_vt, shrd_vt_pre = shrd_vt_pre, shrd_vt\n",
        "\n",
        "    next_block = block + 1\n",
        "\n",
        "    # wait until all threads have computed their sum of products before we move\n",
        "    # to the next block as the shared values will be overridden with the next\n",
        "    # iteration\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    if next_block < blocks_per_grid:\n",
        "      # load next block\n",
        "      shrd_u_pre[local_y, local_x] = 0\n",
        "      if y < u.shape[0] and (next_block * threads_per_block + local_x) < u.shape[1]:\n",
        "        # copy values in transposed order\n",
        "        shrd_u_pre[local_y, local_x] = u[y, next_block * threads_per_block + local_x]\n",
        "\n",
        "      if local_y == 0:\n",
        "        shrd_s_pre[local_x] = 0\n",
        "        if (next_block * threads_per_block + local_x) < s.shape[0]:\n",
        "          # only first row in block loads shrd_s since it's a one-dimensional array\n",
        "          shrd_s_pre[local_x] = s[next_block * threads_per_block + local_x]\n",
        "\n",
        "      shrd_vt_pre[local_y, local_x] = 0\n",
        "      if x < vt.shape[1] and (next_block * threads_per_block + local_y) < vt.shape[0]:\n",
        "        shrd_vt_pre[local_y, local_x] = vt[next_block * threads_per_block + local_y, x]\n",
        "\n",
        "    # start calculating the sum of products for index (y, x) and the current block\n",
        "    for i in range(threads_per_block):\n",
        "      # no checking of boundaries necessary since the warp executes the\n",
        "      # statement anyway and threads out of bound would have to wait anyway\n",
        "\n",
        "      # read values from shred_u in transposed order\n",
        "      sum_of_products += shrd_u[local_y, i] * shrd_s[i] * shrd_vt[i, local_x]\n",
        "\n",
        "  if y < reco.shape[0] and x < reco.shape[1]:\n",
        "    reco[y, x] = sum_of_products\n",
        "\n",
        "def reconstruct_svd_gpu_6(u, s, vt, k):\n",
        "  threads_per_block = 16\n",
        "  reco_h = np.zeros((u.shape[0], vt.shape[1]))\n",
        "\n",
        "  reco_d = cuda.to_device(reco_h)\n",
        "  u_d = cuda.to_device(u[:, 0:k])\n",
        "  s_d = cuda.to_device(s[0:k])\n",
        "  vt_d = cuda.to_device(vt[0:k, :])\n",
        "\n",
        "  grid_y_max = max(u.shape[0], k)\n",
        "  grid_x_max = max(k, vt.shape[1])\n",
        "\n",
        "  n_blocks_x = math.ceil(grid_x_max / threads_per_block)\n",
        "  n_blocks_y = math.ceil(grid_y_max / threads_per_block)\n",
        "\n",
        "  _reconstruct_svd_gpu_6[\n",
        "    (n_blocks_x, n_blocks_y), (threads_per_block, threads_per_block)\n",
        "  ](u_d, s_d, vt_d, reco_d)\n",
        "\n",
        "  return reco_d.copy_to_host()\n",
        "\n",
        "### END SOLUTION"
      ],
      "metadata": {
        "id": "CoAMu7gpvzyN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reco = reconstruct_svd_gpu_6(u, s, vt, u.shape[1])\n",
        "np.testing.assert_array_almost_equal(reco, m, decimal=3)\n"
      ],
      "metadata": {
        "id": "HXqCGw89v9o7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_runtimes(\n",
        "    ['memory optimised', 'preloading shared memory\\n 32 threads per block', 'preloading shared memory\\n 16 threads per block'],\n",
        "    [reconstruct_svd_gpu_2, reconstruct_svd_gpu_5, reconstruct_svd_gpu_6]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "S6hvAXImv_Wm",
        "outputId": "e113e259-4d52-4ef8-d82f-ea4f3580e6ef"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"images/reconstruct_svd_gpu_6.png\" alt=\"Report für Variante 6\" width=\"500\"/>\n",
        "\n",
        "<font color=\"blue\">Diese Optimierungen bringen die Laufzeiten in die Grössenordnung der bisher besten Variante. Tendenziell ist diese sogar leicht schneller als Variante 2. Die Duration konnte laut Report von 92.5 ms auf 85 ms verkürzt werden und es sind entsprechend auch weniger Cylces nötig. Streaming Multiprocessor sind durch die Verkleinerung der Warps wieder beide gleich stark ausgelastet und konnte um 10 Prozentpunkte auf 85 % erhöht werden. \n",
        "\n",
        "Aufgrund der kleineren Blöcke haben sich jedoch die Lesezugriffe aufs Global-Memory erhöht. Dies ist auch beim L1- und L2-Cache erkennbar, durch welche die Zugriffe aufs Global-Memory (Device Memory) laufen. Bei der Occupancy sehen wir, dass die Parameter für Block Size und die Grösse des Shared Memory pro Threadblock und der implizite Wert für die Registers pro Thread hinsichtlich der Warp-Auslaustung optimal gewählt wurden.\n",
        "\n",
        "Die längsten Wartezeiten der Warps fallen nun auf die Zustände *Stall LG Throttle* und *Stall Long Scoreboard*, also warten sie auf die Memory-Komponenten um auf das Global- und Shared-Memory zugreifen zu können.</font>"
      ],
      "metadata": {
        "id": "2S81PrDjYq8k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "t0N9LmNh10gI"
      },
      "source": [
        "### 6 Beschleunigte Rekonstruktion mehrerer Bilder\n",
        "#### 6.1 Implementierung\n",
        "Verwende einige der in bisher gelernten Konzepte, um mehrere Bilder gleichzeitig parallel zu rekonstruieren. Weshalb hast du welche Konzepte für deine Implementierung verwenden? Versuche die GPU konstant auszulasten und so auch die verschiedenen Engines der GPU parallel zu brauchen. Diskutiere in ca. 250-300 Wörtern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3pBEU7310gI",
        "outputId": "ed63b104-8c2b-4a22-9671-0d828c803bbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "putting 700 items in queue\n"
          ]
        }
      ],
      "source": [
        "### BEGIN SOLUTION\n",
        "\n",
        "from gpu_lib import reconstruct_multiple_svd\n",
        "\n",
        "filenames = [os.path.join(folders, name + '.png') for name in names] * 100\n",
        "print(f'putting {len(filenames)} items in queue')\n",
        "reconstruct_multiple_svd(filenames, n_processes=3, max_items_on_gpu=3, min_items_on_gpu=2, verbose=False)\n",
        "\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "qDbRypeY10gI"
      },
      "source": [
        "<font color='blue'>Die GPU besteht aus drei Arten von Komponenten, die unabhängig voneinander Arbeiten ausführen können: H2D, Kernel und D2H. Das Ziel sollte sein, dass alle drei Komponenten jeweils bestmöglich ausgelastet sind. Der Prozess um ein einzelnes Bild zu rekonstruieren besteht jeweils aus mehreren H2D-Tasks, der Ausführung des Kernels und einem D2H-Task. Diese müssen jeweils pro Bild in dieser Reihenfolge ausgeführt werden. Um die GPU nun möglichst gut auszulasten, sollen jeweils mehrere Bilder gleichzeitig verarbeitet werden. So sollte für jede Komponente mindestens eine Arbeit bereitstehen, sobald ihr letzter Task abgeschlossen wurde. Zu Beginn startet die H2D-Komponente mit der Kopie der Matrizen. Sobald dies abgeschlossen ist, wird der Kernel ausgeführt und die H2D-Komponente startet mit den nächsten Matrizen für das Bild. Sobald der Kernel für das erste Bild zu Ende ist, übernimmt die D2H-Komponente für dieses Bild und der Kernel startet mit dem zweiten Bild. Währenddessen beginnt die H2D-Komponente mit dem dritten Bild.\n",
        "\n",
        "Damit die Reihenfolge pro Bild eingehalten werden kann, werden CUDA-Streams eingesetzt. Streams untereinander können gleichzeitig ausgeführt werden, je nach anstehender Aufgabe und verfügbaren Komponenten auf der GPU. Es ist jedoch garantiert, dass die einzelnen Befehle in einem Stream in der Reihenfolge ausgeführt werden, wie sie dem Stream hinzugefügt wurden. Um die Streams genügend schnell befüllen zu können, werden drei Prozesse gestartet und entsprechend auch drei CUDA-Streams. So soll jede GPU-Komponente einen Stream zur Verfügung haben, an dem sie arbeiten kann. Es werden Prozesse und nicht Threads verwendet, da neben der Kommunikation mit der GPU auch die SVD durchgeführt werden muss. Diese wird auf der CPU ausgeführt und ist rechenintensiv. Damit der Standard-Python-Prozess nicht damit blockiert wird und die rechtzeitige Kommunikation mit der GPU sichergestellt werden kann, ist Gleichläufigkeit zwingend. \n",
        "\n",
        "Bei dieser Implementierung kann definiert werden wie viele Bilder pro Stream im Minimum vorhanden sein sollen und wieviele maximal. Mit dem Minimum kann vermieden werden, dass ein Stream leer wird. Wenn das Minimum auf 1 gesetzt wird, werden neue Bilder dem Stream hinzugefügt, wenn die GPU mit dem letzten Bild beginnt. Das Maximum dient dazu zu definieren wie viele Bilder maximal dem Stream hinzugefügt werden sollen, um nicht an die Grenzen des Device-Memory zu stossen. Durch Events kann gezählt werden, wie viele Bilder im Stream bereits verarbeitet wurden und entsprechend reagiert werden. Nach der Rekonstruktion eines Bildes wird diese mit dem Orginalbild abgeglichen. Falls diese nicht übereinstimmen sollte, wird ein Fehler geworfen und der ausführende Prozess bricht ab.\n",
        "\n",
        "Als Kernel wurde die effizienteste Variante, also Nummer 6, verwendet.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "1tqRdLjg10gJ"
      },
      "source": [
        "#### 6.2 Analyse\n",
        "Vergleiche den Speedup für deine parallele Implementierung im Vergleich zur seriellen Rekonstruktion einzelner Bilder. Analysiere und diskutiere in diesem Zusammenhang die Gesetze von Amdahl und Gustafson in ca. 300 Wörtern."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def compare_multi_process_approaches():\n",
        "  filenames = [os.path.join(folders, name + '.png') for name in names] * 300\n",
        "  print(f'using {len(filenames)} items')\n",
        "\n",
        "  start = time.time()\n",
        "  for filename in filenames:\n",
        "    # read image\n",
        "    img = imageio.imread(filename)\n",
        "\n",
        "    # apply SVD to get U, S, V^T\n",
        "    img = img - img.min() / img.max() - img.min() # normalize data\n",
        "    u, s, vt = np.linalg.svd(img, full_matrices=False)\n",
        "\n",
        "    reco = reconstruct_svd_gpu_6(u, s, vt, u.shape[1])\n",
        "    np.testing.assert_array_almost_equal(reco, img, decimal=3)\n",
        "\n",
        "  time_for_serial = time.time() - start\n",
        "\n",
        "  results = [{'name': 'serial', 'duration': time_for_serial}]\n",
        "\n",
        "  for n_processes in range(1, 5):\n",
        "    print(f'starting with {n_processes} process(es)')\n",
        "    start = time.time()\n",
        "    reconstruct_multiple_svd(filenames, n_processes=n_processes, max_items_on_gpu=2, min_items_on_gpu=1, verbose=False)\n",
        "    results.append({'name': f'{n_processes} process(es)', 'duration': time.time() - start})\n",
        "\n",
        "  results_df = pd.DataFrame(results)\n",
        "\n",
        "  plt.figure(figsize = (12, 7))\n",
        "  plt.scatter(\n",
        "      results_df.name,\n",
        "      results_df.duration\n",
        "  )\n",
        "  plt.title('Laufzeiten')\n",
        "  plt.xlabel('Variante')\n",
        "  plt.ylabel('Dauer [s]')\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "F-2j0NDPk5sL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_multi_process_approaches()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "H8VKDVrWk9FF",
        "outputId": "5ecb1dbb-74e4-4000-d887-7322f7b598f4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using 2100 items\n",
            "starting with 1 process(es)\n",
            "starting with 2 process(es)\n",
            "starting with 3 process(es)\n",
            "starting with 4 process(es)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "G67OGrLS10gJ"
      },
      "source": [
        "<font color='blue'>Bei diesen kleinen Matrizen braucht es einige Bilder, damit sich der Einsatz von Multiprocessing wirklich lohnt. Der Overhead zum Starten von Prozessen und dem Prozessmanagement allgemein benötigt  Zeit.  \n",
        "\n",
        "Dies ist was Amdahl und Gustafson mit ihren Gesetzen aussagen möchten: Um den Speedup zu berechnen, muss der Code in den seriell ausgeführten und den parallel ausführbaren Teil aufgeteilt werden. Amdahl's Law sagt aus, dass der Code nur soweit beschleunigt werden kann, bis die Laufzeit des seriellen Codes erreicht wurde. Beide unterschlagen jedoch den Overhead, der durch die Parallelisierung verursacht wird nicht vernachlässigbar ist. Der Unterschied zwischen Amdahl und Gustafson ist, dass Amdahl beschreibt, wie stark die Laufzeit durch Gleichläufigkeit beschleunigt werden kann, währenddessen Gustafson definiert, wie viele Operationen zusätzlich durch mehr Prozessorkerne in der gleichen Zeit ausgeführt werden können.\n",
        "\n",
        "Da SVD bei dieser Implementierung auf der CPU ausgeführt wird, könnten bei grösseren Bildern die Prozesse ins Hintertreffen gelangen und der GPU nicht mehr rechtzeitig neue Matrizen zur Rekonstruktion übergeben. In diesem Fall könnte man die Anzahl der Prozesse erhöhen, bis die Anzahl Prozessorkerne auf dem System erreicht wurden.\n",
        "\n",
        "Zu beachten ist, dass dieser Code bei Google Colab ausgeführt wurde, wo in der Regel nur einzelne Prozessorkerne zur Verfügung stehen und so das wirkliche Potenzial von Multiprocessing nicht gezeigt werden kann.\n",
        "\n",
        "In diesem Fall konnte durch Multiprocessing keine Verbesserung bei der Laufzeit erzielt werden. Mit einem Prozess ist man erstaunlicherweise etwa gleich schnell oder sogar leicht schneller wie wenn man die Matrixmultiplikation direkt im Haupt-Prozess auslöst. Mit mehr Prozessen wird die Ausführung noch stark verlängert. Dies liegt wohl daran, dass die GPU pro Prozess einen eigenen Kontext mit CUDA-Streams startet. Dadurch werden die Berechnungen nicht parallelisiert, sondern es wird dafür gesorgt, dass jeweils nur ein Prozess die GPU verwendet. Dies kann man umgehen, indem man den Multi-Process-Service von Nvidia startet. CUDA sendet dann alle GPU-Befehle an diesen Prozess, der diese dann an die GPU weiterleitet, so dass für diese alle Befehle von einem einzelnen Prozess stammen. Den MPS gibt es jedoch nur auf Linux-Systemen.\n",
        "\n",
        "Mit folgenden Befehlen könnte der MPS gestartet werden. Dies scheint aber keinen Unterschied zu machen. Die Multi-Process-Varianten sind noch immer nicht wirklich schneller als der serielle Ansatz. Möglicherweise funktioniert der MPS nicht wie gewünscht auf Google Colab.</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export CUDA_VISIBLE_DEVICES=0\n",
        "!export CUDA_MPS_PIPE_DIRECTORY=/tmp/nvidia-mps\n",
        "!export CUDA_MPS_LOG_DIRECTORY=/tmp/nvidia-log\n",
        "!nvidia-smi -i 0 -c EXCLUSIVE_PROCESS\n",
        "!nvidia-cuda-mps-control -d\n",
        "!export CUDA_MPS_PIPE_DIRECTORY=/tmp/nvidia-mps\n",
        "!export CUDA_MPS_LOG_DIRECTORY=/tmp/nvidia-log"
      ],
      "metadata": {
        "id": "8Ba1DoNv2D8R"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_multi_process_approaches()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "pa2i2k3bzuot",
        "outputId": "e0f20d66-84a0-4d82-bf75-9fb1dbd538d0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using 2100 items\n",
            "starting with 1 process(es)\n",
            "starting with 2 process(es)\n",
            "starting with 3 process(es)\n",
            "starting with 4 process(es)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "VuJpsXdO10gJ"
      },
      "source": [
        "#### 6.3 Komponentendiagramm\n",
        "\n",
        "Erstelle das Komponentendiagramm dieser Mini-Challenge für die Rekunstruktion mehrere Bilder mit einer GPU-Implementierung. Erläutere das Komponentendigramm in 3-4 Sätzen.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "q-3MVyIZ10gJ"
      },
      "source": [
        "<img src=\"reconstruction-components.png\" alt=\"Komponentendiagramm für parallele Rekonstruktion\" width=\"500\"/>\n",
        "\n",
        "<font color='blue'>Dieses Komponentendiagramm zeigt einerseits die beteiligten Komponenten und auch was auf der CPU pro Prozess ausgeführt wird und wie die GPU pro Stream arbeitet. Dabei wurde der Ablauf möglichst einfach gehalten und die Aktionen im Prozess und im Stream wiederholen sich bis alle Bilder abgearbeitet wurden. \n",
        "\n",
        "Die Prozesse auf der CPU und die Streams auf der GPU arbeiten bis auf die Synchronisation mittels Events unabhängig voneinander. Die CPU übergibt der GPU Tasks (Kopieren H2D, Ausführen des Kernels und Kopieren D2H), die diese ausführt, sobald Ressourcen für die jeweilige Aktion verfügbar sind. Die einzelnen Komponenten auf der GPU arbeiten dabei für unterschiedliche Streams und entsprechend auch unterschiedliche Prozesse. Dabei beachten sie aber die Reihenfolge der Tasks im Stream.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tPwBkA510gK"
      },
      "source": [
        "### 7 Reflexion\n",
        "\n",
        "Reflektiere die folgenden Themen indem du in 3-5 Sätzen begründest und anhand von Beispielen erklärst."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyZYqo6010gK"
      },
      "source": [
        "1: Was sind deiner Meinung nach die 3 wichtigsten Prinzipien bei der Beschleunigung von Code?\n",
        "\n",
        "<font color='blue'>Bevor Code bezüglich seiner Laufzeit optimiert wird, sollte untersucht werden, wo dessen Bottlenecks und rechenintensiven Bereiche liegen, damit man geeignete Anpassungen vornehmen kann. Je nach Problem besteht die Möglichkeit zur Parallelisierung gewisser Code-Teil (Prozesse, Threads), der Vektorisierung von Rechenoperationen und der Auslagerung von Teilen auf die GPU. Bei vielen I/O-Zugriffen lohnt sich bereits der Einsatz von Multithreading. Bei rechenintensiven Operationen muss auf Vektorisierung, Multiprocessing oder die GPU zurückgegriffen werden. Dabei sollte Amdahl's und Gustafson's Law nicht vergessen werden.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAJLmN7F10gK"
      },
      "source": [
        "2: Welche Rechenarchitekturen der Flynnschen Taxonomie wurden in dieser Mini-Challenge wie verwendet?\n",
        "\n",
        "<font color='blue'>Der CPU-Code setzt grundsätzlich auf *Single Instruction, Single Data* und der GPU-Kernel ist auf Basis von *Single Instruction, Multiple Data* aufgebaut. Bei der CPU wird jedes Statement einzeln mit den jeweiligen Daten abgearbeitet, auch wenn andere Prozesse die gleiche Operation mit anderen Daten durchführen. Bei der GPU wird ein Kernel gleichzeitig und schrittweise in einem ganzen Warp abgearbeitet.\n",
        "\n",
        "Aktuelle CPUs enthalten auch Komponenten mit einer SIMD-Architektur (zum Beispiel AVX bei Intel). Bei dieser Mini-Challenge wird numpy verwendet, das einige Operationen auch mittels SIMD auf der CPU optimiert: [numpy Dokumentation](https://numpy.org/devdocs/reference/simd/index.html)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8LPwpR710gK"
      },
      "source": [
        "3: Haben wir es in dieser Mini-Challenge hauptsächlich mit CPU- oder IO-Bound Problemen zu tun? Nenne Beispiele.\n",
        "\n",
        "<font color='blue'>Da sich die Bilder bereits im Arbeitsspeicher befinden, haben wir es vor allem mit CPU-Problemen zu tun. Die Berechnung hat eine Komplexität von $O(n^3)$ und ist somit sehr rechenintensiv.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sR_rs5B510gK"
      },
      "source": [
        "4: Wie könnte diese Anwendung in einem Producer-Consumer Design konzipiert werden?\n",
        "\n",
        "<font color='blue'>Wenn der gesamte Prozess (Zerlegung, Rekonstruktion, Überprüfung) damit umgesetzt werden sollte, könnte man die einzelnen Schritte als separate Services implementieren. Ein Producer führt SVD aus, ein weiterer Producer führt die Rekonstruktion durch und ein Consumer überprüft die Rekonstruktion mit den ursprünglichen Daten. So kann die Hardware für die einzelnen Services auch entsprechend dimensioniert werden. Für die Rekonstruktion sind sicher Server mit GPU-Leistung nötig, auf die bei der Überprüfung auch verzichtet werden kann. Die Hardware-Leistung kann so ideal auf die Anforderungen der einzelnen Schritte angepasst werden, so dass es zu keinem Bottleneck kommt. Für die Kommunikation zwischen den Services müsste eine passende Methode gefunden werden, da die Bilder und die Rekonstruktion sehr gross sind, was insbesondere zu Problemen führen kann, wenn die Services keine schnelle Verbindung untereinander haben (und sich zum Beispiel in unterschiedlichen Rechenzentren befinden). Die Daten könnten auf einem zentralen und schnellen Datenspeicher abgelegt werden und über den Broker nur die ID der einzelnen Datenblöcke übermittelt werden. So bleiben die Messages klein, was beispielsweise bei Kafka von Vorteil ist.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQtna3S210gL"
      },
      "source": [
        "5: Was sind die wichtigsten Grundlagen, um mehr Performance auf der GPU in dieser Mini-Challenge zu erreichen?\n",
        "\n",
        "<font color='blue'>Die Verwendung der GPU ist mit Overhead verbunden, da Daten zwischen Host und Device kopiert werden müssen. Deshalb muss dieser Overhead kompensiert wird, was durch die Umsetzung des *Single Instruction, Multiple Data*-Paradigma ermöglicht werden kann. Anweisungen sollen auf so vielen Daten wie möglich gleichzeitig ausgeführt werden können. Zudem sollen die Memory-Operationen auf der GPU (vor allem auf dessen Global-Memory) so stark reduziert werden wie nur möglich. Wenn auf dieses zugegriffen wird, sollen diese Zugriffe möglichst coallesced sein, damit die Zugriffe kombiniert werden können und nicht für jeden Thread ein eigener langsamer Zugriff durchgeführt werden muss. Beim Shared-Memory sollen die Zugriffe keine Bank Conflicts auslösen, damit auch hier die Zugriffe parallelisiert werden können.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "uwLJyI_810gL"
      },
      "source": [
        "6: Reflektiere die Mini-Challenge in ca. 300-500 Zeichen. Was ist gut gelaufen? Wo gab es Probleme? Wo hast du mehr Zeit als geplant gebraucht? Was hast du dabei gelernt? Was hat dich überrascht? Was hättest du zusätzlich lernen wollen? Würdest du gewisse Fragestellungen anders formulieren? Wenn ja, wie?\n",
        "\n",
        "<font color='blue'>Ich fand die Mini-Challenge von der Thematik her sehr spannend. Programmierung auf der GPU habe ich bisher noch nicht gemacht und konnte mir auch nicht vorstellen, wie das konkret funktioniert und auf was man dort achten muss. Ich war erstaunt, dass es sogar für die interpretierte Sprache Python eine saubere Abstraktion von CUDA gibt. Die Umsetzung war komplexer als ich das erwartet hatte. Es brauchte eine Weile bis ich die verschiedenen Konzepte und Komponenten der GPU (Threads, Warps, Threadblöcke, Shared Memory, etc.) verstanden hatte.\n",
        "\n",
        "Multihreading und Multiprocessing habe ich zu einem Teil auch schon bei der ersten Mini-Challenge anwenden können, wobei ich dieses Mal wieder einige neue Werkzeuge ausprobieren konnte. Dabei bin ich auch auf Probleme gestossen, wie zum Beispiel dass CUDA plötzlich unter gewissen Umständen Probleme mit mehreren Prozessen hatte. Mit der Fork-Strategie wurden auch CUDA-Objekte in die Subprozesse übernommen, was nicht erlaubt war. Bei der Spawn-Strategie musste ich anschliessend auch die Queue speziell aus diesem Spawn-Prozess erstellen, damit diese korrekt funktionierte.\n",
        "\n",
        "Bei einer nächsten Durchführung dieser Mini-Challenge würde ich statt den kleinen ADNI-Bildern, viel grössere und auch die Menge dieser vergrössern, damit die Optimierungen auch wirklich gemessen werden können. Bei so kleinen Datenmengen fällt der Effekt klein aus oder die Optimierungen sind langsamer als die ursprüngliche Version, da der Overhead zu gross ist.\n",
        "\n",
        "Ich fand es gut, dass die Mini-Challenge mit einfachen Aufgaben begonnen hat, so dass man sich an die Thematik und die Problemstellung gewöhnen kann. Ich würde aber die einzelnen Aufgaben nicht mehr so klar strukturieren, sondern mehr Freiraum geben, so dass man selbst entscheiden könnte, ob man nochmals zwei Numpy-Broadcasting-Varianten implementieren möchte, wenn man dieses Konzept bereits bei anderen Varianten eingesetzt hat.</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pGDGNNyb8au9"
      },
      "execution_count": 26,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}