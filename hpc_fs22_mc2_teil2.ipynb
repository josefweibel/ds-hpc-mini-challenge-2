{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLfRBCjm10f-"
      },
      "source": [
        "# HPC Mini-Challenge 2 - Beschleunigung in Data Science\n",
        "## Teil 2: GPU\n",
        "#### FHNW - FS22\n",
        "\n",
        "Original von S. Suter, angepasst für das HS22 von S. Marcin\n",
        "\n",
        "Abgabe von: <font color='blue'>Joseph Weibel</font>\n",
        "\n",
        "#### Ressourcen\n",
        "* [Überblick GPU Programmierung](https://www.cherryservers.com/blog/introduction-to-gpu-programming-with-cuda-and-python)\n",
        "* [CUDA Basic Parts](https://nyu-cds.github.io/python-gpu/02-cuda/)\n",
        "* [Accelerate Code with CuPy](https://towardsdatascience.com/heres-how-to-use-cupy-to-make-numpy-700x-faster-4b920dda1f56)\n",
        "* Vorlesungen und Beispiele aus dem Informatikkurs PAC (parallel computing), siehe resourcen\n",
        "* CSCS \"High-Performance Computing with Python\" Kurs, Tag 3: \n",
        "    - JIT Numba GPU 1 + 2\n",
        "    - https://youtu.be/E4REVbCVxNQ\n",
        "    - https://github.com/eth-cscs/PythonHPC/tree/master/numba-cuda\n",
        "    - Siehe auch aktuelles Tutorial von 2021\n",
        "* [Google CoLab](https://colab.research.google.com/) oder ggf. eigene GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ny9XUwE10gA",
        "outputId": "b4fe63d9-3416-4eb0-a428-333a4ef97beb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (0.56.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba) (4.13.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.18 in /usr/local/lib/python3.8/dist-packages (from numba) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba) (3.11.0)\n"
          ]
        }
      ],
      "source": [
        "#!pip install numba"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz9j6XIIJoqn",
        "outputId": "a2516608-d300-4648-d2b7-e665e875b0ad"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec 15 09:39:02 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P0    29W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfDMy5al10gB",
        "outputId": "7e5e74f9-749d-4015-c4da-e5155315fcf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 4 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.       ,  1.       ,  1.4142135, ..., 63.97656  , 63.98437  ,\n",
              "       63.992188 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Dummy Beispiel zum testen mit Numba\n",
        "\n",
        "import math\n",
        "from numba import vectorize\n",
        "import numpy as np\n",
        "\n",
        "@vectorize(['float32(float32)'], target='cuda')\n",
        "def gpu_sqrt(x):\n",
        "    return math.sqrt(x)\n",
        "  \n",
        "\n",
        "a = np.arange(4096,dtype=np.float32)\n",
        "gpu_sqrt(a)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBfhyWv1SnQV",
        "outputId": "28e60908-6f50-407b-aea0-74a73882d406"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "subfolder = '001'\n",
        "folders = os.path.join('/content/drive/MyDrive/adni_png', subfolder)\n",
        "\n",
        "images = np.empty([7,256,170])\n",
        "idx = 0\n",
        "names = []\n",
        "for filename in os.listdir(folders):\n",
        "    if filename.endswith('.png') and '145' in filename:\n",
        "        with open(os.path.join(folders, filename), 'r') as f:\n",
        "            im = imageio.imread(f.name)\n",
        "            names.insert(idx,f.name[-17:-4])\n",
        "            images[idx,:,:] = im\n",
        "            print (names[idx], im.shape)\n",
        "            idx += 1\n",
        "            \n",
        "print(images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "C8bXzEUrSh7-",
        "outputId": "2c6e05c2-78eb-4323-c318-2de64d71cd25"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-28980cef9b40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'145'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/adni_png/001'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = images[0]\n",
        "m = m -m.min() / m.max() - m.min() # normalize data \n",
        "u,s,vt = np.linalg.svd(m, full_matrices=False)"
      ],
      "metadata": {
        "id": "mS8O4WkCTuRK"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "m = np.random.normal(size=(1000, 1000))\n",
        "u, s, vt = np.linalg.svd(m, full_matrices=False)"
      ],
      "metadata": {
        "id": "iW81HIzP5E1n"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg9v73Xr10gC"
      },
      "source": [
        "### 5 GPU Rekonstruktion\n",
        "\n",
        "Implementiere eine SVD-Rekonstruktionsvariante auf der GPU oder in einem hybriden Setting. Code aus dem ersten Teil darf dabei verwendet werden. Wähle  bewusst, welche Teile des Algorithms in einem GPU Kernel implementiert werden und welche effizienter auf der CPU sind. Ziehe dafür Erkenntnisse aus dem ersten Teil mit ein. Es muss mindestens eine Komponente des Algorithmuses in einem GPU-Kernel implementiert werden. Dokumentiere Annahmen, welche du ggf. zur Vereinfachung triffst. Evaluiere, ob du mit CuPy oder Numba arbeiten möchtest. Diskutiere deine Entscheidungen in 150-200 Wörtern. \n",
        "\n",
        "Links:\n",
        "* [Examples: Matrix Multiplikation](https://numba.readthedocs.io/en/latest/cuda/examples.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bQ_svru010gC"
      },
      "outputs": [],
      "source": [
        "### BEGIN SOLUTION\n",
        "from numba import cuda, float32\n",
        "import math\n",
        "\n",
        "\n",
        "@cuda.jit\n",
        "def _reconstruct_svd_gpu_1(u, s, vt, reco):\n",
        "  x, y = cuda.grid(2)\n",
        "\n",
        "  if x < u.shape[0] and y < vt.shape[0]:\n",
        "    sum = 0\n",
        "    for k in range(s.shape[0]):\n",
        "      sum += u[x, k] * s[k] * vt[k, y]\n",
        "\n",
        "    reco[x, y] = sum\n",
        "\n",
        "def reconstruct_svd_gpu_1(u, s, vt, k, threads_per_block=32):\n",
        "  reco_h = np.zeros((u.shape[0], vt.shape[1]))\n",
        "\n",
        "  reco_d = cuda.to_device(reco_h)\n",
        "  u_d = cuda.to_device(u[:, 0:k])\n",
        "  s_d = cuda.to_device(s[0:k])\n",
        "  vt_d = cuda.to_device(vt[0:k, :])\n",
        "\n",
        "  n_blocks_x = math.ceil(u.shape[0] / threads_per_block)\n",
        "  n_blocks_y = math.ceil(vt.shape[0] / threads_per_block)\n",
        "\n",
        "  _reconstruct_svd_gpu_1[\n",
        "    (n_blocks_x, n_blocks_y), (threads_per_block, threads_per_block)\n",
        "  ](u_d, s_d, vt_d, reco_d)\n",
        "\n",
        "  return reco_d.copy_to_host()\n",
        "\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "reco = reconstruct_svd_gpu_1(u, s, vt, u.shape[1])\n",
        "np.testing.assert_array_almost_equal(reco, m, decimal=3)"
      ],
      "metadata": {
        "id": "7Yp2DK46SbZL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7r60ZT_10gD"
      },
      "source": [
        "<font color='blue'>Bei dieser einfachen Implementierung wird die gesamte Berechnung auf der GPU vorgenommen. Jeder Thread ist für ein einzelnes Pixel in der Rekonstruktion verantwortlich. Das Kürzen der Matrizen und Vektoren auf n Komponenten wird auf der CPU vorgenommen, beziehungsweise werden nur die nötigen Elemente auf die GPU kopiert. Dadurch wird verhindert, dass Elemente zur GPU kopiert werden, die dort gar nicht benötigt werden.\n",
        "\n",
        "Die Anzahl Threads pro Block kann dabei frei definiert werden. Kleinere Grössen können sinnvoll sein, um dadurch die Rekonstruktionsgrösse genau aufteilen zu können, so dass möglichst keine Threads leer laufen. Bei einer Breite von 2000 px wäre es sinnvoller 25 oder 16 statt 32 zu verwenden.\n",
        "TODO: stimmt das?\n",
        "\n",
        "Es wird numba verwendet, da damit die grundelegenden GPU-Operationen simuliert werden können. Zudem kann damit Python-Code geschrieben werden, der dann autoamtisch in C-Code übersetzt wird.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQz_TGwG10gD"
      },
      "source": [
        "#### 5.2 GPU-Kernel Performance\n",
        "\n",
        "##### 5.2.1 Blocks und Strided Access\n",
        "\n",
        "Links: \n",
        "* [Examples: Matrix Multiplikation](https://numba.readthedocs.io/en/latest/cuda/examples.html)\n",
        "* [NVIDIA Kapitel zu \"Strided Access\"](https://spaces.technik.fhnw.ch/multimediathek/file/cuda-best-practices-in-c)\n",
        "* https://developer.nvidia.com/blog/cublas-strided-batched-matrix-multiply/\n",
        "* https://developer.nvidia.com/blog/how-access-global-memory-efficiently-cuda-c-kernels/\n",
        "\n",
        "Führe 2-3 Experimente mit unterschiedlichen Blockkonfigurationen und Strided Access durch, auf welchen dein GPU-Kernel arbeitet. Messe die Performance des GPU-Kernels mittels geeigneten Funktionen. Welche Blockgrösse und welcher Strided Access hat sich bei dir basierend auf deinen Experimenten als am erfolgreichsten erwiesen? Welches sind deiner Meinung nach die Gründe dafür? Wie sind die Performance Unterschiede zwischen deiner CPU und PGU Implementierung? Diskutiere deine Analyse in ca. 200 Wörtern und ggf. mit Grafiken. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.environ[\"NUMBA_ENABLE_CUDASIM\"] = \"1\"\n"
      ],
      "metadata": {
        "id": "fi3hKRXbZXZ9"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3aYPqmRk10gE"
      },
      "outputs": [],
      "source": [
        "### BEGIN SOLUTION\n",
        "@cuda.jit\n",
        "def _reconstruct_svd_gpu_2(u, s, vt, reco):\n",
        "  # each thread calculates the sum of products for a specific index (x, y)\n",
        "\n",
        "  x, y = cuda.grid(2)\n",
        "  local_x = cuda.threadIdx.x\n",
        "  local_y = cuda.threadIdx.y\n",
        "  threads_per_block = 32 # cuda.blockDim.x but must be constant\n",
        "  blocks_per_grid = cuda.gridDim.x\n",
        "\n",
        "  shrd_u = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "  shrd_s = cuda.shared.array(shape=(threads_per_block,), dtype=float32)\n",
        "  shrd_vt = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "\n",
        "  sum_of_products = float32(0.)\n",
        "  for block in range(blocks_per_grid):\n",
        "    # calculate sum of products per block\n",
        "    # the block is only moved to get the other values in the matrices u, s and vt\n",
        "    # the index for which the sum of product is calculated remains the same\n",
        "\n",
        "    shrd_u[local_y, local_x] = 0\n",
        "    if y < u.shape[0] and (block * threads_per_block + local_x) < u.shape[1]:\n",
        "      shrd_u[local_y, local_x] = u[y, block * threads_per_block + local_x]\n",
        "\n",
        "    if local_y == 0:\n",
        "      shrd_s[local_x] = 0\n",
        "      if (block * threads_per_block + local_x) < s.shape[0]:\n",
        "        # only first row in block loads shrd_s since it's a one-dimensional array\n",
        "        shrd_s[local_x] = s[block * threads_per_block + local_x]\n",
        "\n",
        "    shrd_vt[local_y, local_x] = 0\n",
        "    if x < vt.shape[1] and (block * threads_per_block + local_y) < vt.shape[0]:\n",
        "      shrd_vt[local_y, local_x] = vt[block * threads_per_block + local_y, x]\n",
        "\n",
        "    # wait until all tpb x tpb elements are filled\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    # start calculating the sum of products for index (y, x)\n",
        "    for i in range(threads_per_block):\n",
        "      # no checking of boundaries necessary since the warp executes the\n",
        "      # statement anyway and threads out of bound would have to wait anyway\n",
        "      sum_of_products += shrd_u[local_y, i] * shrd_s[i] * shrd_vt[i, local_x]\n",
        "\n",
        "    # wait until all threads have computed their sum of products before we move\n",
        "    # to the next block as the shared values will be overridden with the next\n",
        "    # iteration\n",
        "    cuda.syncthreads()\n",
        "\n",
        "  if y < reco.shape[0] and x < reco.shape[1]:\n",
        "    reco[y, x] = sum_of_products\n",
        "\n",
        "def reconstruct_svd_gpu_2(u, s, vt, k, threads_per_block=32):\n",
        "  reco_h = np.zeros((u.shape[0], vt.shape[1]))\n",
        "\n",
        "  reco_d = cuda.to_device(reco_h)\n",
        "  u_d = cuda.to_device(u[:, 0:k])\n",
        "  s_d = cuda.to_device(s[0:k])\n",
        "  vt_d = cuda.to_device(vt[0:k, :])\n",
        "\n",
        "  grid_y_max = max(u.shape[0], k)\n",
        "  grid_x_max = max(k, vt.shape[1])\n",
        "\n",
        "  n_blocks_x = math.ceil(grid_x_max / threads_per_block)\n",
        "  n_blocks_y = math.ceil(grid_y_max / threads_per_block)\n",
        "\n",
        "  _reconstruct_svd_gpu_2[\n",
        "    (n_blocks_x, n_blocks_y), (threads_per_block, threads_per_block)\n",
        "  ](u_d, s_d, vt_d, reco_d)\n",
        "\n",
        "  return reco_d.copy_to_host()\n",
        "\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reco = reconstruct_svd_gpu_2(u, s, vt, u.shape[1])\n",
        "np.testing.assert_array_almost_equal(reco, m, decimal=3)\n"
      ],
      "metadata": {
        "id": "rxzNDrzE6SwG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQJeUtV610gF"
      },
      "source": [
        "<font color='blue'>Die erste Version hat ein schlechtes Verhältnis von Memory- zu Computation-Operationen. Es wird bei jeder Berechnung dreimal aufs Memory zugegriffen, ohne dass diese Werte nochmals verwendet werden. Diese optimierte Variante kopiert nun blockweise die benötigten Werte ins Shared-Memory wo sie von allen Threads desselben Blocks ebenfalls verwendet werden können. Da bei diesen Matrixmultiplikationen sehr viele Elemente wiederverwendet werden können, ist diese Implementierung um einiges schneller als die letzte, auch wenn nach wie vor alle Elemente mehrmals kopiert werden, da sie auch von anderen Blocks verwendet werden.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJZydur_10gF"
      },
      "source": [
        "##### 5.2.2 Memoryallokation auf der GPU\n",
        "Führe 2-3 Experimente durch in welchem du unterschiedliche Varianten des Transfers der Daten bzw. der Memory-Allokation auf die GPU miteinander vergleichst. Messe die Varianten mittels geeigneten Methoden. Als Beispiel können hier z.B. unterschiedlich grosse Packages an Daten auf die GPU kopiert und dann verarbeitet werden oder die Daten werden in unterschiedliche Memory-Typen geladen.\n",
        "\n",
        "Links:\n",
        "* [Best Practices Memory Optimizations](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#memory-optimizations)\n",
        "* [Examples: Matrix Multiplikation und Shared Memory](https://numba.readthedocs.io/en/latest/cuda/examples.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Antwort\n",
        "\n",
        "<font color='blue'></font>"
      ],
      "metadata": {
        "id": "XdDmxc38f0Lg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tZCkT52c10gF"
      },
      "outputs": [],
      "source": [
        "### BEGIN SOLUTION\n",
        "@cuda.jit\n",
        "def _reconstruct_svd_gpu_3(u, s, vt, reco):\n",
        "  # each thread calculates the sum of products for a specific index (x, y)\n",
        "\n",
        "  x, y = cuda.grid(2)\n",
        "  local_x = cuda.threadIdx.x\n",
        "  local_y = cuda.threadIdx.y\n",
        "  threads_per_block = 32 # cuda.blockDim.x but must be constant\n",
        "  blocks_per_grid = cuda.gridDim.x\n",
        "\n",
        "  shrd_u = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "  shrd_s = cuda.shared.array(shape=(threads_per_block,), dtype=float32)\n",
        "  shrd_vt = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "\n",
        "  sum_of_products = float32(0.)\n",
        "  for block in range(blocks_per_grid):\n",
        "    # calculate sum of products per block\n",
        "    # the block is only moved to get the other values in the matrices u, s and vt\n",
        "    # the index for which the sum of product is calculated remains the same\n",
        "\n",
        "    shrd_u[local_y, local_x] = 0\n",
        "    if y < u.shape[0] and (block * threads_per_block + local_x) < u.shape[1]:\n",
        "      # copy values in transposed order\n",
        "      shrd_u[local_y, local_x] = u[y, block * threads_per_block + local_x]\n",
        "\n",
        "    if local_y == 0:\n",
        "      shrd_s[local_x] = 0\n",
        "      if (block * threads_per_block + local_x) < s.shape[0]:\n",
        "        # only first row in block loads shrd_s since it's a one-dimensional array\n",
        "        shrd_s[local_x] = s[block * threads_per_block + local_x]\n",
        "\n",
        "    shrd_vt[local_x, local_y] = 0\n",
        "    if x < vt.shape[1] and (block * threads_per_block + local_y) < vt.shape[0]:\n",
        "      shrd_vt[local_x, local_y] = vt[block * threads_per_block + local_y, x]\n",
        "\n",
        "    # wait until all tpb x tpb elements are filled\n",
        "    cuda.syncthreads()\n",
        "\n",
        "    # start calculating the sum of products for index (y, x)\n",
        "    for i in range(threads_per_block):\n",
        "      # no checking of boundaries necessary since the warp executes the\n",
        "      # statement anyway and threads out of bound would have to wait anyway\n",
        "\n",
        "      # read values from shred_u in transposed order\n",
        "      sum_of_products += shrd_u[local_y, i] * shrd_s[i] * shrd_vt[local_x, i]\n",
        "\n",
        "    # wait until all threads have computed their sum of products before we move\n",
        "    # to the next block as the shared values will be overridden with the next\n",
        "    # iteration\n",
        "    cuda.syncthreads()\n",
        "\n",
        "  if y < reco.shape[0] and x < reco.shape[1]:\n",
        "    reco[y, x] = sum_of_products\n",
        "\n",
        "def reconstruct_svd_gpu_3(u, s, vt, k, threads_per_block=32):\n",
        "  reco_h = np.zeros((u.shape[0], vt.shape[1]))\n",
        "\n",
        "  reco_d = cuda.to_device(reco_h)\n",
        "  u_d = cuda.to_device(u[:, 0:k])\n",
        "  s_d = cuda.to_device(s[0:k])\n",
        "  vt_d = cuda.to_device(vt[0:k, :])\n",
        "\n",
        "  grid_y_max = max(u.shape[0], k)\n",
        "  grid_x_max = max(k, vt.shape[1])\n",
        "\n",
        "  n_blocks_x = math.ceil(grid_x_max / threads_per_block)\n",
        "  n_blocks_y = math.ceil(grid_y_max / threads_per_block)\n",
        "\n",
        "  _reconstruct_svd_gpu_2[\n",
        "    (n_blocks_x, n_blocks_y), (threads_per_block, threads_per_block)\n",
        "  ](u_d, s_d, vt_d, reco_d)\n",
        "\n",
        "  return reco_d.copy_to_host()\n",
        "\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reco = reconstruct_svd_gpu_3(u, s, vt, u.shape[1])\n",
        "np.testing.assert_array_almost_equal(reco, m, decimal=3)\n"
      ],
      "metadata": {
        "id": "nz_P46K2frSw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW5QvzaY10gG"
      },
      "source": [
        "Was sind deine Erkenntnisse bzgl. GPU-Memory-Allokation und des Daten-Transferes auf due GPU? Wie hast du ggf. deine Implementierung aus 5.1 angepasst? Diskutiere deine Antwort in ca. 150-200 Wörtern."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQIv_HuO10gG"
      },
      "source": [
        "<font color='blue'>Diese Implementierung versucht Bank-Conflicts beim Zugriff auf das Shared-Memory zu vermeiden. Auf `shrt_vt` wurde bisher in einem Warp jeweils pro Iteration auf dieselbe Spalte zugegriffen. Dadurch kam es zu 32 Bank Conflicts, was dazu führte, dass jedes Element separat aus dem Shared-Memory abgerufen werden musste. Neu ist `shrt_vt` transponiert, so dass im Warp jeweils eine ganze Zeile abgerufen werden kann.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mcY4-4w10gG"
      },
      "source": [
        "##### 5.2.3 Bonus: Memoryoptimierung\n",
        "Optimiere die Memory-Allokation in deiner Implementierung, so dass du einen Leistungssteigerung zu einer anderen Variante demonstrieren kannst."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Antwort\n"
      ],
      "metadata": {
        "id": "DzhQFio_0sn0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jR7tKA0-10gH"
      },
      "outputs": [],
      "source": [
        "### BEGIN SOLUTION\n",
        "@cuda.jit\n",
        "def _reconstruct_svd_gpu_4(u, s, vt, reco):\n",
        "  # each thread calculates the sum of products for a specific index (x, y)\n",
        "\n",
        "  x, y = cuda.grid(2)\n",
        "  local_x = cuda.threadIdx.x\n",
        "  local_y = cuda.threadIdx.y\n",
        "  threads_per_block = 32 # cuda.blockDim.x but must be constant\n",
        "  blocks_per_grid = cuda.gridDim.x\n",
        "\n",
        "  shrd_u = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "  shrd_s = cuda.shared.array(shape=(threads_per_block,), dtype=float32)\n",
        "  shrd_vt = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "  shrd_u_pre = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "  shrd_s_pre = cuda.shared.array(shape=(threads_per_block,), dtype=float32)\n",
        "  shrd_vt_pre = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)\n",
        "\n",
        "  shrd_u_pre[local_y, local_x] = 0\n",
        "  if y < u.shape[0] and local_x < u.shape[1]:\n",
        "    # copy values in transposed order\n",
        "    shrd_u_pre[local_y, local_x] = u[y, local_x]\n",
        "\n",
        "  if local_y == 0:\n",
        "    shrd_s_pre[local_x] = 0\n",
        "    if local_x < s.shape[0]:\n",
        "      # only first row in block loads shrd_s since it's a one-dimensional array\n",
        "      shrd_s_pre[local_x] = s[local_x]\n",
        "\n",
        "  shrd_vt_pre[local_x, local_y] = 0\n",
        "  if x < vt.shape[1] and local_y < vt.shape[0]:\n",
        "    shrd_vt_pre[local_x, local_y] = vt[local_y, x]\n",
        "\n",
        "  # wait until all tpb x tpb elements are filled\n",
        "  cuda.syncthreads()\n",
        "\n",
        "  sum_of_products = float32(0.)\n",
        "  for block in range(blocks_per_grid):\n",
        "    # calculate sum of products per block\n",
        "    # the block is only moved to get the other values in the matrices u, s and vt\n",
        "    # the index for which the sum of product is calculated remains the same\n",
        "\n",
        "    # swap shared memory blocks\n",
        "    shrd_u, shrd_u_pre = shrd_u_pre, shrd_u\n",
        "    shrd_s, shrd_s_pre = shrd_s_pre, shrd_s\n",
        "    shrd_vt, shrd_vt_pre = shrd_vt_pre, shrd_vt\n",
        "\n",
        "    next_block = block + 1\n",
        "\n",
        "    # load next block\n",
        "    shrd_u_pre[local_y, local_x] = 0\n",
        "    if y < u.shape[0] and (next_block * threads_per_block + local_x) < u.shape[1]:\n",
        "      # copy values in transposed order\n",
        "      shrd_u_pre[local_y, local_x] = u[y, next_block * threads_per_block + local_x]\n",
        "\n",
        "    if local_y == 0:\n",
        "      shrd_s_pre[local_x] = 0\n",
        "      if (next_block * threads_per_block + local_x) < s.shape[0]:\n",
        "        # only first row in block loads shrd_s since it's a one-dimensional array\n",
        "        shrd_s_pre[local_x] = s[next_block * threads_per_block + local_x]\n",
        "\n",
        "    shrd_vt_pre[local_x, local_y] = 0\n",
        "    if x < vt.shape[1] and (next_block * threads_per_block + local_y) < vt.shape[0]:\n",
        "      shrd_vt_pre[local_x, local_y] = vt[next_block * threads_per_block + local_y, x]\n",
        "\n",
        "    # start calculating the sum of products for index (y, x) and the current block\n",
        "    for i in range(threads_per_block):\n",
        "      # no checking of boundaries necessary since the warp executes the\n",
        "      # statement anyway and threads out of bound would have to wait anyway\n",
        "\n",
        "      # read values from shred_u in transposed order\n",
        "      sum_of_products += shrd_u[local_y, i] * shrd_s[i] * shrd_vt[local_x, i]\n",
        "\n",
        "    # wait until all threads have computed their sum of products before we move\n",
        "    # to the next block as the shared values will be overridden with the next\n",
        "    # iteration\n",
        "    cuda.syncthreads()\n",
        "\n",
        "  if y < reco.shape[0] and x < reco.shape[1]:\n",
        "    reco[y, x] = sum_of_products\n",
        "\n",
        "def reconstruct_svd_gpu_4(u, s, vt, k, threads_per_block=32):\n",
        "  reco_h = np.zeros((u.shape[0], vt.shape[1]))\n",
        "\n",
        "  reco_d = cuda.to_device(reco_h)\n",
        "  u_d = cuda.to_device(u[:, 0:k])\n",
        "  s_d = cuda.to_device(s[0:k])\n",
        "  vt_d = cuda.to_device(vt[0:k, :])\n",
        "\n",
        "  grid_y_max = max(u.shape[0], k)\n",
        "  grid_x_max = max(k, vt.shape[1])\n",
        "\n",
        "  n_blocks_x = math.ceil(grid_x_max / threads_per_block)\n",
        "  n_blocks_y = math.ceil(grid_y_max / threads_per_block)\n",
        "\n",
        "  _reconstruct_svd_gpu_4[\n",
        "    (n_blocks_x, n_blocks_y), (threads_per_block, threads_per_block)\n",
        "  ](u_d, s_d, vt_d, reco_d)\n",
        "\n",
        "  return reco_d.copy_to_host()\n",
        "\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reco = reconstruct_svd_gpu_4(u, s, vt, u.shape[1])\n",
        "np.testing.assert_array_almost_equal(reco, m, decimal=3)\n"
      ],
      "metadata": {
        "id": "qPUsmKNS6oH-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>Bei dieser Optimierung passiert der Kopiervorgang vom Shared-Memory ins globale Memory nun asynchron zu den Berechnungen. Währenddem das Resultat für den aktuellen Block berechnet wird, werden bereits die Elemente des nächsten Blocks kopiert, so dass sie teilweise oder gar vollständig bereitstehen, wenn die Berechnungen des nächsten Blocks anstehen. Dazu wird jedoch doppelt soviel Speicher im Shared-Memory benötigt. Die GPU kann so aber besser ausgelastet werden.</font>"
      ],
      "metadata": {
        "id": "3RL_2wM05HyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### BEGIN SOLUTION\n",
        "import pandas as pd\n",
        "import timeit\n",
        "\n",
        "def plot_runtimes(names, fncs):\n",
        "    times = []\n",
        "    for fnc in fncs:\n",
        "        times.append(timeit.repeat(lambda: fnc(u, s, vt, u.shape[0]), number=3, repeat=30))\n",
        "        \n",
        "    times = np.array(times)\n",
        "    \n",
        "    y = times.mean(axis=1)\n",
        "    plt.figure(figsize = (10, 5))\n",
        "    plt.errorbar(\n",
        "        names,\n",
        "        y,\n",
        "        times.std(axis=1),\n",
        "        linestyle='None',\n",
        "        marker='o', \n",
        "        capsize=10\n",
        "    )\n",
        "    plt.title('Laufzeiten')\n",
        "    plt.xlabel('Variante')\n",
        "    plt.ylabel('Dauer [s] (log)')\n",
        "    plt.yscale('log')\n",
        "    plt.show()\n",
        "\n",
        "    results = pd.DataFrame({'fnc': names, 'mean duration (s)': y})\n",
        "    results.fnc = results.fnc.str.replace('\\n', '')\n",
        "    results\n",
        "\n",
        "plot_runtimes(\n",
        "    ['basic', 'memory optimised', 'avoiding bank conflicts', 'preloading shared memory'],\n",
        "    [reconstruct_svd_gpu_1, reconstruct_svd_gpu_2, reconstruct_svd_gpu_3, reconstruct_svd_gpu_4]\n",
        ")\n",
        "\n",
        "\n",
        "### END SOLUTION"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "4PWZ5f6U6k7L",
        "outputId": "0de2e74c-226e-4b11-8742-3179a5835c5a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>Beim Vergleich der Laufzeiten dieser vier GPU-Varianten lässt sich schnell erkennen, dass die Basic-Variante die Vorteile einer GPU nicht nutzt, da sie das Paradigma Single-Instruction-Multiple-Data nicht anwendet. Für jede einzelne Berechnung müssen drei Werte aus dem Global-Memory der GPU kopiert werden, was viel Zeit kostet.\n",
        "\n",
        "Die optimierte Variante kopiert blockweise Werte der zwei Matrizen und des Vektors in das Shared-Memory, wo die Werte vom gesamten Threadblock verwendet werden können. Dadurch wird die Anzahl Zugriffe aufs Global-Memory stark reduziert, was sich einer viel kürzeren Laufzeit bemerkbar macht. Durch die Vermeidung von Bank-Conflicts bei der dritten Version verringert sich die Laufzeit nochmals, aber nur minim. Das Preloading vom Global-Memory ins Shared-Memory scheint nicht zu funktioniert. Die Laufzeit ist bei dieser Version ziemlich hoch. Möglicherweise können durch den doppelt so hohen Shared-Memoryverbrauch nicht mehr gleich viele Threads in einem Threadblock gleichzeitig ausgeführt werden, da für die Verwaltung der Threads nicht ausreichend Memory zur Verfügung steht. Die reduzierte Gleichläufigkeit hat dabei einen viel grösseren negativen Effekt als das Vorladen des Memorys wieder wett machen kann.</font>"
      ],
      "metadata": {
        "id": "XqCPW0p2_qcR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-a9oB8m10gH"
      },
      "source": [
        "#### 5.3 NVIDIA Profiler\n",
        "\n",
        "Benutze einen Performance Profiler von NVIDIA, um Bottlenecks in deinem Code zu identifizieren bzw. unterschiedliche Implementierungen (Blocks, Memory etc.) zu vergleichen. \n",
        "\n",
        "* Siehe Beispiel example_profiling_CUDA.ipynb\n",
        "* [Nsight](https://developer.nvidia.com/nsight-visual-studio-edition) für das Profiling des Codes und die Inspektion der Ergebnisse (neuste Variante)\n",
        "* [nvprof](https://docs.nvidia.com/cuda/profiler-users-guide/index.html#nvprof-overview)\n",
        "* [Nvidia Visual Profiler](https://docs.nvidia.com/cuda/profiler-users-guide/index.html#visual)\n",
        "\n",
        "> Du kannst NVIDIA Nsights Systems und den Nvidia Visual Profiler auf deinem PC installieren und die Leistungsergebnisse aus einer Remote-Instanz visualisieren, auch wenn du keine GPU an/in deinem PC hast. Dafür kannst du die ``*.qdrep`` Datei generieren und danach lokal laden.\n",
        "\n",
        "\n",
        "Dokumentiere deine Analyse ggf. mit 1-2 Visualisierungen und beschreibe in 3-5 Sätzen, welche Bottlenecks du gefunden bzw. entschärft hast."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX2oulVk10gH"
      },
      "source": [
        "<font color='blue'>Antwort hier eingeben inkl. Bild.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "t0N9LmNh10gI"
      },
      "source": [
        "### 6 Beschleunigte Rekonstruktion mehrerer Bilder\n",
        "#### 6.1 Implementierung\n",
        "Verwende einige der in bisher gelernten Konzepte, um mehrere Bilder gleichzeitig parallel zu rekonstruieren. Weshalb hast du welche Konzepte für deine Implementierung verwenden? Versuche die GPU konstant auszulasten und so auch die verschiedenen Engines der GPU parallel zu brauchen. Diskutiere in ca. 250-300 Wörtern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "d3pBEU7310gI"
      },
      "outputs": [],
      "source": [
        "### BEGIN SOLUTION\n",
        "\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "qDbRypeY10gI"
      },
      "source": [
        "<font color='blue'>Antwort hier eingeben</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "1tqRdLjg10gJ"
      },
      "source": [
        "#### 6.2 Analyse\n",
        "Vergleiche den Speedup für deine parallele Implementierung im Vergleich zur seriellen Rekonstruktion einzelner Bilder. Analysiere und diskutiere in diesem Zusammenhang die Gesetze von Amdahl und Gustafson in ca. 300 Wörtern."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "G67OGrLS10gJ"
      },
      "source": [
        "<font color='blue'>Antwort hier eingeben</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "VuJpsXdO10gJ"
      },
      "source": [
        "#### 6.3 Komponentendiagramm\n",
        "\n",
        "Erstelle das Komponentendiagramm dieser Mini-Challenge für die Rekunstruktion mehrere Bilder mit einer GPU-Implementierung. Erläutere das Komponentendigramm in 3-4 Sätzen.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "q-3MVyIZ10gJ"
      },
      "source": [
        "<font color='blue'>Antwort hier eingeben inkl. Bild(ern).</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tPwBkA510gK"
      },
      "source": [
        "### 7 Reflexion\n",
        "\n",
        "Reflektiere die folgenden Themen indem du in 3-5 Sätzen begründest und anhand von Beispielen erklärst."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyZYqo6010gK"
      },
      "source": [
        "1: Was sind deiner Meinung nach die 3 wichtigsten Prinzipien bei der Beschleunigung von Code?\n",
        "\n",
        "<font color='blue'>Antwort hier eingeben</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAJLmN7F10gK"
      },
      "source": [
        "2: Welche Rechenarchitekturen der Flynnschen Taxonomie wurden in dieser Mini-Challenge wie verwendet?\n",
        "\n",
        "<font color='blue'>Antwort hier eingeben</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8LPwpR710gK"
      },
      "source": [
        "3: Haben wir es in dieser Mini-Challenge hauptsächlich mit CPU- oder IO-Bound Problemen zu tun? Nenne Beispiele.\n",
        "\n",
        "<font color='blue'>Da sich die Bilder bereits im Arbeitsspeicher befinden, haben wir es vor allem mit CPU-Problemen zu tun. Die Berechnung hat eine Komplexität von $O(n^3)$ und ist somit sehr rechenintensiv.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sR_rs5B510gK"
      },
      "source": [
        "4: Wie könnte diese Anwendung in einem Producer-Consumer Design konzipiert werden?\n",
        "\n",
        "<font color='blue'>Antwort hier eingeben</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQtna3S210gL"
      },
      "source": [
        "5: Was sind die wichtigsten Grundlagen, um mehr Performance auf der GPU in dieser Mini-Challenge zu erreichen?\n",
        "\n",
        "<font color='blue'>Antwort hier eingeben</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "uwLJyI_810gL"
      },
      "source": [
        "6: Reflektiere die Mini-Challenge in ca. 300-500 Zeichen. Was ist gut gelaufen? Wo gab es Probleme? Wo hast du mehr Zeit als geplant gebraucht? Was hast du dabei gelernt? Was hat dich überrascht? Was hättest du zusätzlich lernen wollen? Würdest du gewisse Fragestellungen anders formulieren? Wenn ja, wie?\n",
        "\n",
        "<font color='blue'>Antwort hier eingeben</font>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}